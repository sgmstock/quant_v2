"""
è‚¡ç¥¨åˆ†ç±»æŒ‡æ•°æ˜ å°„å™¨

æ ¹æ®stock_basic_proè¡¨ä¸­çš„å­—æ®µå€¼ï¼Œå°†è‚¡ç¥¨åˆ†ç±»åˆ°ä¸åŒçš„æŒ‡æ•°ä¸­ï¼š
- å›½ä¼æŒ‡æ•° (100001.ZS)
- Bè‚¡æŒ‡æ•° (100002.ZS)  
- Hè‚¡æŒ‡æ•° (100003.ZS)
- è€è‚¡æŒ‡æ•° (100004.ZS)
- å¤§é«˜æŒ‡æ•° (100005.ZS)
- é«˜ä»·æŒ‡æ•° (100006.ZS)
- ä½ä»·æŒ‡æ•° (100007.ZS)
- æ¬¡æ–°æŒ‡æ•° (100008.ZS)
- è¶…å¼ºæŒ‡æ•° (100009.ZS)
"""

import pandas as pd
import sqlite3
import os
from sqlalchemy import create_engine
from datetime import datetime, timedelta
import numpy as np


class StockCategoryIndexMapper:
    """è‚¡ç¥¨åˆ†ç±»æŒ‡æ•°æ˜ å°„å™¨"""
    
    def __init__(self, db_path=None):
        """
        åˆå§‹åŒ–æ˜ å°„å™¨
        
        Args:
            db_path: æ•°æ®åº“è·¯å¾„ï¼Œé»˜è®¤ä¸ºé¡¹ç›®ä¸­çš„quant_system.db
        """
        if db_path is None:
            # ä½¿ç”¨ç›¸å¯¹äºå½“å‰æ–‡ä»¶çš„è·¯å¾„ï¼Œç¡®ä¿è·¯å¾„æ­£ç¡®
            current_dir = os.path.dirname(os.path.abspath(__file__))
            db_path = os.path.join(current_dir, '..', 'databases', 'quant_system.db')
            db_path = os.path.abspath(db_path)
        
        self.db_path = db_path
        self.engine = create_engine(f'sqlite:///{db_path}')
        
        # å®šä¹‰æŒ‡æ•°æ˜ å°„è¡¨
        self.index_mapping = {
            'å›½ä¼': {'index_code': '100001.ZS', 'index_name': 'å›½ä¼æŒ‡æ•°'},
            'Bè‚¡': {'index_code': '100002.ZS', 'index_name': 'Bè‚¡æŒ‡æ•°'},
            'Hè‚¡': {'index_code': '100003.ZS', 'index_name': 'Hè‚¡æŒ‡æ•°'},
            'è€è‚¡': {'index_code': '100004.ZS', 'index_name': 'è€è‚¡æŒ‡æ•°'},
            'å¤§é«˜': {'index_code': '100005.ZS', 'index_name': 'å¤§é«˜æŒ‡æ•°'},
            'é«˜ä»·': {'index_code': '100006.ZS', 'index_name': 'é«˜ä»·æŒ‡æ•°'},
            'ä½ä»·': {'index_code': '100007.ZS', 'index_name': 'ä½ä»·æŒ‡æ•°'},
            'æ¬¡æ–°': {'index_code': '100008.ZS', 'index_name': 'æ¬¡æ–°æŒ‡æ•°'},
            'è¶…å¼º': {'index_code': '100009.ZS', 'index_name': 'è¶…å¼ºæŒ‡æ•°'}
        }
    
    def get_stock_categories(self):
        """
        ä»stock_basic_proè¡¨è·å–è‚¡ç¥¨åˆ†ç±»ä¿¡æ¯
        
        Returns:
            pd.DataFrame: åŒ…å«è‚¡ç¥¨ä»£ç ã€åç§°å’Œåˆ†ç±»å­—æ®µçš„DataFrame
        """
        try:
            # æŸ¥è¯¢stock_basic_proè¡¨
            query = """
                SELECT stock_code, stock_name, å›½ä¼, Bè‚¡, Hè‚¡, è€è‚¡, å¤§é«˜, é«˜ä»·, ä½ä»·, æ¬¡æ–°, è¶…å¼º
                FROM stock_basic_pro
                WHERE stock_code IS NOT NULL
            """
            
            df = pd.read_sql_query(query, self.engine)
            print(f"âœ“ æˆåŠŸè¯»å–stock_basic_proè¡¨ï¼Œå…±{len(df)}æ¡è®°å½•")
            
            return df
            
        except Exception as e:
            print(f"âœ— è¯»å–stock_basic_proè¡¨å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def create_category_mapping_table(self):
        """
        åˆ›å»ºè‚¡ç¥¨åˆ†ç±»æ˜ å°„è¡¨
        
        Returns:
            pd.DataFrame: è‚¡ç¥¨åˆ†ç±»æ˜ å°„è¡¨
        """
        # è·å–è‚¡ç¥¨åˆ†ç±»ä¿¡æ¯
        df_stocks = self.get_stock_categories()
        
        if df_stocks.empty:
            print("âœ— æ— æ³•è·å–è‚¡ç¥¨æ•°æ®")
            return pd.DataFrame()
        
        # åˆ›å»ºæ˜ å°„è¡¨
        mapping_records = []
        
        for _, stock in df_stocks.iterrows():
            stock_code = stock['stock_code']
            stock_name = stock['stock_name']
            
            # æ£€æŸ¥æ¯ä¸ªåˆ†ç±»å­—æ®µ
            for category, index_info in self.index_mapping.items():
                if stock[category] == 1 or stock[category] is True:
                    mapping_records.append({
                        'stock_code': stock_code,
                        'stock_name': stock_name,
                        'category': category,
                        'index_code': index_info['index_code'],
                        'index_name': index_info['index_name']
                    })
        
        df_mapping = pd.DataFrame(mapping_records)
        
        if not df_mapping.empty:
            print(f"âœ“ åˆ›å»ºåˆ†ç±»æ˜ å°„è¡¨å®Œæˆï¼Œå…±{len(df_mapping)}æ¡æ˜ å°„è®°å½•")
        else:
            print("âš  æœªæ‰¾åˆ°ä»»ä½•ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
        
        return df_mapping
    
    def get_stocks_by_category(self, category):
        """
        æ ¹æ®åˆ†ç±»è·å–è‚¡ç¥¨åˆ—è¡¨
        
        Args:
            category: åˆ†ç±»åç§°ï¼ˆå¦‚'å›½ä¼'ã€'Bè‚¡'ç­‰ï¼‰
            
        Returns:
            list: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        """
        if category not in self.index_mapping:
            print(f"âœ— æ— æ•ˆçš„åˆ†ç±»åç§°: {category}")
            return []
        
        df_stocks = self.get_stock_categories()
        
        if df_stocks.empty:
            return []
        
        # ç­›é€‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨
        filtered_stocks = df_stocks[
            (df_stocks[category] == 1) | (df_stocks[category] == True)
        ]
        
        stock_codes = filtered_stocks['stock_code'].tolist()
        print(f"âœ“ {category}åˆ†ç±»å…±æœ‰{len(stock_codes)}åªè‚¡ç¥¨")
        
        return stock_codes
    
    def get_all_category_summary(self):
        """
        è·å–æ‰€æœ‰åˆ†ç±»çš„ç»Ÿè®¡æ‘˜è¦
        
        Returns:
            pd.DataFrame: åˆ†ç±»ç»Ÿè®¡æ‘˜è¦
        """
        df_stocks = self.get_stock_categories()
        
        if df_stocks.empty:
            return pd.DataFrame()
        
        summary_records = []
        
        for category, index_info in self.index_mapping.items():
            count = df_stocks[
                (df_stocks[category] == 1) | (df_stocks[category] == True)
            ].shape[0]
            
            summary_records.append({
                'category': category,
                'index_code': index_info['index_code'],
                'index_name': index_info['index_name'],
                'stock_count': count
            })
        
        df_summary = pd.DataFrame(summary_records)
        df_summary = df_summary.sort_values('stock_count', ascending=False)
        
        print("âœ“ åˆ†ç±»ç»Ÿè®¡æ‘˜è¦:")
        for _, row in df_summary.iterrows():
            print(f"  {row['category']} ({row['index_code']}): {row['stock_count']}åªè‚¡ç¥¨")
        
        return df_summary
    
    def save_mapping_to_database(self, table_name='stock_category_mapping'):
        """
        å°†æ˜ å°„è¡¨ä¿å­˜åˆ°æ•°æ®åº“
        
        Args:
            table_name: è¡¨å
        """
        df_mapping = self.create_category_mapping_table()
        
        if df_mapping.empty:
            print("âœ— æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return False
        
        try:
            # åˆ é™¤å·²å­˜åœ¨çš„è¡¨
            with self.engine.connect() as conn:
                conn.execute(f"DROP TABLE IF EXISTS {table_name}")
            
            # ä¿å­˜æ–°è¡¨
            df_mapping.to_sql(table_name, self.engine, index=False, if_exists='replace')
            
            print(f"âœ“ æˆåŠŸä¿å­˜æ˜ å°„è¡¨åˆ°æ•°æ®åº“: {table_name}")
            print(f"  å…±{len(df_mapping)}æ¡è®°å½•")
            
            return True
            
        except Exception as e:
            print(f"âœ— ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    def export_mapping_to_csv(self, filename=None):
        """
        å¯¼å‡ºæ˜ å°„è¡¨åˆ°CSVæ–‡ä»¶
        
        Args:
            filename: æ–‡ä»¶åï¼Œé»˜è®¤ä¸ºå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶å
        """
        df_mapping = self.create_category_mapping_table()
        
        if df_mapping.empty:
            print("âœ— æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
            return False
        
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'stock_category_mapping_{timestamp}.csv'
        
        try:
            df_mapping.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"âœ“ æˆåŠŸå¯¼å‡ºæ˜ å°„è¡¨åˆ°CSVæ–‡ä»¶: {filename}")
            return True
            
        except Exception as e:
            print(f"âœ— å¯¼å‡ºCSVæ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    def create_index_k_daily_table(self):
        """
        åˆ›å»ºindex_k_dailyè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        """
        try:
            conn = sqlite3.connect(self.db_path)
            
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS index_k_daily (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                index_code TEXT NOT NULL,
                index_name TEXT NOT NULL,
                trade_date TEXT NOT NULL,
                open REAL,
                high REAL,
                low REAL,
                close REAL,
                volume INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(index_code, trade_date)
            )
            """
            
            conn.execute(create_table_sql)
            
            # åˆ›å»ºç´¢å¼•
            conn.execute("CREATE INDEX IF NOT EXISTS idx_index_k_daily_code ON index_k_daily (index_code)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_index_k_daily_date ON index_k_daily (trade_date)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_index_k_daily_code_date ON index_k_daily (index_code, trade_date)")
            
            conn.commit()
            conn.close()
            print("âœ… index_k_dailyè¡¨åˆ›å»ºæˆåŠŸæˆ–å·²å­˜åœ¨")
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºindex_k_dailyè¡¨å¤±è´¥: {e}")
    
    def get_stock_kline_data(self, stock_codes, start_date=None, end_date=None):
        """
        è·å–è‚¡ç¥¨çš„Kçº¿æ•°æ®
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
            
        Returns:
            pd.DataFrame: Kçº¿æ•°æ®
        """
        try:
            if not stock_codes:
                return pd.DataFrame()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            placeholders = ','.join(['?' for _ in stock_codes])
            query = f"""
                SELECT stock_code, trade_date, open, high, low, close, volume
                FROM k_daily 
                WHERE stock_code IN ({placeholders})
            """
            params = list(stock_codes)
            
            if start_date:
                query += " AND trade_date >= ?"
                params.append(start_date)
            
            if end_date:
                query += " AND trade_date <= ?"
                params.append(end_date)
            
            query += " ORDER BY trade_date, stock_code"
            
            # ä½¿ç”¨sqlite3ç›´æ¥è¿æ¥è€Œä¸æ˜¯pandasçš„read_sql_query
            conn = sqlite3.connect(self.db_path)
            df = pd.read_sql_query(query, conn, params=params)
            conn.close()
            
            print(f"âœ“ è·å–Kçº¿æ•°æ®æˆåŠŸï¼Œå…±{len(df)}æ¡è®°å½•")
            
            return df
            
        except Exception as e:
            print(f"âœ— è·å–Kçº¿æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def calculate_index_kline(self, stock_codes, index_code, index_name, start_date=None, end_date=None):
        """
        è®¡ç®—æ¿å—æŒ‡æ•°çš„Kçº¿æ•°æ®
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            index_code: æŒ‡æ•°ä»£ç 
            index_name: æŒ‡æ•°åç§°
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            
        Returns:
            pd.DataFrame: æŒ‡æ•°Kçº¿æ•°æ®
        """
        if not stock_codes:
            print(f"âš  {index_name}æ²¡æœ‰æˆåˆ†è‚¡ï¼Œè·³è¿‡è®¡ç®—")
            return pd.DataFrame()
        
        print(f"ğŸ“Š è®¡ç®—{index_name}({index_code})æŒ‡æ•°...")
        print(f"   æˆåˆ†è‚¡æ•°é‡: {len(stock_codes)}")
        
        # è·å–è‚¡ç¥¨Kçº¿æ•°æ®
        df_kline = self.get_stock_kline_data(stock_codes, start_date, end_date)
        
        if df_kline.empty:
            print(f"âš  {index_name}æ²¡æœ‰Kçº¿æ•°æ®ï¼Œè·³è¿‡è®¡ç®—")
            return pd.DataFrame()
        
        # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—æŒ‡æ•°
        index_data = []
        
        for trade_date, group in df_kline.groupby('trade_date'):
            # è¿‡æ»¤æ‰åœç‰Œè‚¡ç¥¨ï¼ˆæˆäº¤é‡ä¸º0æˆ–ç¼ºå¤±ï¼‰
            active_stocks = group[group['volume'] > 0].copy()
            
            if len(active_stocks) == 0:
                continue
            
            # è®¡ç®—å¸‚å€¼åŠ æƒå¹³å‡ä»·æ ¼
            # ä½¿ç”¨æ”¶ç›˜ä»·ä½œä¸ºæƒé‡ï¼ˆç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ç”¨æµé€šå¸‚å€¼ï¼‰
            weights = active_stocks['close'] / active_stocks['close'].sum()
            
            # è®¡ç®—åŠ æƒå¹³å‡çš„å¼€é«˜ä½æ”¶
            index_open = (active_stocks['open'] * weights).sum()
            index_high = (active_stocks['high'] * weights).sum()
            index_low = (active_stocks['low'] * weights).sum()
            index_close = (active_stocks['close'] * weights).sum()
            
            # è®¡ç®—æ€»æˆäº¤é‡
            index_volume = active_stocks['volume'].sum()
            
            index_data.append({
                'index_code': index_code,
                'index_name': index_name,
                'trade_date': trade_date,
                'open': round(index_open, 2),
                'high': round(index_high, 2),
                'low': round(index_low, 2),
                'close': round(index_close, 2),
                'volume': int(index_volume)
            })
        
        df_index = pd.DataFrame(index_data)
        
        if not df_index.empty:
            print(f"âœ“ {index_name}æŒ‡æ•°è®¡ç®—å®Œæˆï¼Œå…±{len(df_index)}ä¸ªäº¤æ˜“æ—¥")
        else:
            print(f"âš  {index_name}æŒ‡æ•°è®¡ç®—å¤±è´¥ï¼Œæ— æœ‰æ•ˆæ•°æ®")
        
        return df_index
    
    def save_index_data_to_db(self, index_data, table_name='index_k_daily', replace_existing=True):
        """
        ä¿å­˜æŒ‡æ•°æ•°æ®åˆ°æ•°æ®åº“
        
        Args:
            index_data: æŒ‡æ•°æ•°æ®DataFrame
            table_name: è¡¨å
            replace_existing: æ˜¯å¦æ›¿æ¢å·²å­˜åœ¨çš„æ•°æ®
        """
        if index_data.empty:
            print("âš  æ²¡æœ‰æŒ‡æ•°æ•°æ®å¯ä¿å­˜")
            return False
        
        try:
            # ç¡®ä¿è¡¨å­˜åœ¨
            self.create_index_k_daily_table()
            
            if replace_existing:
                # å…ˆåˆ é™¤å·²å­˜åœ¨çš„æ•°æ®ï¼Œå†æ’å…¥æ–°æ•°æ®
                for _, row in index_data.iterrows():
                    delete_query = """
                        DELETE FROM index_k_daily 
                        WHERE index_code = ? AND trade_date = ?
                    """
                    conn = sqlite3.connect(self.db_path)
                    conn.execute(delete_query, (row['index_code'], row['trade_date']))
                    conn.commit()
                    conn.close()
                
                # æ’å…¥æ–°æ•°æ®
                index_data.to_sql(table_name, self.engine, if_exists='append', index=False)
                print(f"âœ“ æˆåŠŸä¿å­˜{len(index_data)}æ¡æŒ‡æ•°æ•°æ®åˆ°{table_name}è¡¨ï¼ˆå·²æ›¿æ¢é‡å¤æ•°æ®ï¼‰")
            else:
                # ç›´æ¥è¿½åŠ ï¼Œé‡åˆ°é‡å¤ä¼šæŠ¥é”™
                index_data.to_sql(table_name, self.engine, if_exists='append', index=False)
                print(f"âœ“ æˆåŠŸä¿å­˜{len(index_data)}æ¡æŒ‡æ•°æ•°æ®åˆ°{table_name}è¡¨")
            
            return True
            
        except Exception as e:
            print(f"âœ— ä¿å­˜æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")
            return False
    
    def calculate_all_category_indices(self, start_date=None, end_date=None, save_to_db=True, replace_existing=True):
        """
        è®¡ç®—æ‰€æœ‰åˆ†ç±»æŒ‡æ•°çš„Kçº¿æ•°æ®
        
        Args:
            start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
            end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼'YYYY-MM-DD'
            save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
            replace_existing: æ˜¯å¦æ›¿æ¢å·²å­˜åœ¨çš„æ•°æ®
            
        Returns:
            dict: å„åˆ†ç±»æŒ‡æ•°çš„æ•°æ®
        """
        print("ğŸš€ å¼€å§‹è®¡ç®—æ‰€æœ‰åˆ†ç±»æŒ‡æ•°...")
        
        # è·å–æ‰€æœ‰åˆ†ç±»çš„ç»Ÿè®¡ä¿¡æ¯
        summary = self.get_all_category_summary()
        
        if summary.empty:
            print("âœ— æ²¡æœ‰åˆ†ç±»æ•°æ®å¯è®¡ç®—")
            return {}
        
        all_index_data = {}
        total_records = 0
        
        # è®¡ç®—æ¯ä¸ªåˆ†ç±»çš„æŒ‡æ•°
        for _, row in summary.iterrows():
            category = row['category']
            index_code = row['index_code']
            index_name = row['index_name']
            
            # è·å–è¯¥åˆ†ç±»çš„è‚¡ç¥¨åˆ—è¡¨
            stock_codes = self.get_stocks_by_category(category)
            
            # è®¡ç®—æŒ‡æ•°Kçº¿æ•°æ®
            index_data = self.calculate_index_kline(
                stock_codes, index_code, index_name, start_date, end_date
            )
            
            if not index_data.empty:
                all_index_data[category] = index_data
                total_records += len(index_data)
                
                # ä¿å­˜åˆ°æ•°æ®åº“
                if save_to_db:
                    self.save_index_data_to_db(index_data, replace_existing=replace_existing)
        
        print(f"âœ… æ‰€æœ‰åˆ†ç±»æŒ‡æ•°è®¡ç®—å®Œæˆï¼")
        print(f"   å…±è®¡ç®—{len(all_index_data)}ä¸ªæŒ‡æ•°")
        print(f"   æ€»è®°å½•æ•°: {total_records}")
        
        return all_index_data
    
    def get_index_performance_summary(self, index_code, days=30):
        """
        è·å–æŒ‡æ•°è¡¨ç°æ‘˜è¦
        
        Args:
            index_code: æŒ‡æ•°ä»£ç 
            days: ç»Ÿè®¡å¤©æ•°
            
        Returns:
            dict: è¡¨ç°æ‘˜è¦
        """
        try:
            # è·å–æœ€è¿‘Nå¤©çš„æ•°æ®
            query = """
                SELECT trade_date, open, high, low, close, volume
                FROM index_k_daily 
                WHERE index_code = ?
                ORDER BY trade_date DESC
                LIMIT ?
            """
            
            conn = sqlite3.connect(self.db_path)
            df = pd.read_sql_query(query, conn, params=[index_code, days])
            conn.close()
            
            if df.empty:
                return {}
            
            # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
            latest_close = df.iloc[0]['close']
            oldest_close = df.iloc[-1]['close']
            total_return = (latest_close - oldest_close) / oldest_close * 100
            
            max_price = df['high'].max()
            min_price = df['low'].min()
            avg_volume = df['volume'].mean()
            
            return {
                'index_code': index_code,
                'latest_close': latest_close,
                'total_return_pct': round(total_return, 2),
                'max_price': max_price,
                'min_price': min_price,
                'avg_volume': int(avg_volume),
                'trading_days': len(df)
            }
            
        except Exception as e:
            print(f"âœ— è·å–æŒ‡æ•°è¡¨ç°æ‘˜è¦å¤±è´¥: {e}")
            return {}


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºä½¿ç”¨æ–¹æ³•"""
    print("=== è‚¡ç¥¨åˆ†ç±»æŒ‡æ•°æ˜ å°„å™¨æ¼”ç¤º ===\n")
    
    # åˆ›å»ºæ˜ å°„å™¨å®ä¾‹
    mapper = StockCategoryIndexMapper()
    
    # 1. è·å–æ‰€æœ‰åˆ†ç±»çš„ç»Ÿè®¡æ‘˜è¦
    print("1. è·å–åˆ†ç±»ç»Ÿè®¡æ‘˜è¦:")
    summary = mapper.get_all_category_summary()
    print()
    
    # 2. è·å–ç‰¹å®šåˆ†ç±»çš„è‚¡ç¥¨åˆ—è¡¨ï¼ˆä»¥å›½ä¼ä¸ºä¾‹ï¼‰
    print("2. è·å–å›½ä¼è‚¡ç¥¨åˆ—è¡¨:")
    guoqi_stocks = mapper.get_stocks_by_category('å›½ä¼')
    if guoqi_stocks:
        print(f"   å‰10åªå›½ä¼è‚¡ç¥¨: {guoqi_stocks[:10]}")
    print()
    
    # 3. åˆ›å»ºå®Œæ•´çš„æ˜ å°„è¡¨
    print("3. åˆ›å»ºå®Œæ•´æ˜ å°„è¡¨:")
    mapping_df = mapper.create_category_mapping_table()
    if not mapping_df.empty:
        print(f"   æ˜ å°„è¡¨é¢„è§ˆï¼ˆå‰5æ¡ï¼‰:")
        print(mapping_df.head().to_string(index=False))
    print()
    
    # 4. ä¿å­˜åˆ°æ•°æ®åº“
    print("4. ä¿å­˜æ˜ å°„è¡¨åˆ°æ•°æ®åº“:")
    mapper.save_mapping_to_database()
    print()
    
    # 5. å¯¼å‡ºåˆ°CSV
    print("5. å¯¼å‡ºæ˜ å°„è¡¨åˆ°CSV:")
    mapper.export_mapping_to_csv()
    print()
    
    # 6. è®¡ç®—æ¿å—æŒ‡æ•°ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰
    print("6. è®¡ç®—æ¿å—æŒ‡æ•°å¹¶ä¿å­˜åˆ°index_k_dailyè¡¨:")
    print("   è®¡ç®—æœ€è¿‘30å¤©çš„æŒ‡æ•°æ•°æ®...")
    
    # # è®¾ç½®æ—¥æœŸèŒƒå›´ï¼ˆæœ€è¿‘30å¤©ï¼‰
    # end_date = datetime.now().strftime('%Y-%m-%d')
    # start_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')
        # å®šä¹‰å‚æ•°
    start_date = '2020-02-03'
    end_date = '2025-09-11'
    
    # è®¡ç®—æ‰€æœ‰åˆ†ç±»æŒ‡æ•°
    all_index_data = mapper.calculate_all_category_indices(
        start_date=start_date, 
        end_date=end_date, 
        save_to_db=True
    )
    print()
    
    # 7. æ˜¾ç¤ºæŒ‡æ•°è¡¨ç°æ‘˜è¦
    print("7. æŒ‡æ•°è¡¨ç°æ‘˜è¦ï¼ˆæœ€è¿‘30å¤©ï¼‰:")
    for category, index_info in mapper.index_mapping.items():
        if category in all_index_data:
            performance = mapper.get_index_performance_summary(index_info['index_code'], days=30)
            if performance:
                print(f"   {index_info['index_name']}: æ”¶ç›˜ä»·={performance['latest_close']}, "
                      f"æ¶¨è·Œå¹…={performance['total_return_pct']}%, "
                      f"äº¤æ˜“å¤©æ•°={performance['trading_days']}")
    print()
    
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    main()
