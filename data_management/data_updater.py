"""
æ—¥çº¿æ•°æ®æ›´æ–°ä¸å‘¨æœŸè½¬æ¢è„šæœ¬

åŠŸèƒ½ï¼š
1. æä¾›ä¸¤ç§æ—¥çº¿æ›´æ–°æ¨¡å¼ï¼š
   - [é¦–é€‰] ä»æŒ‡å®šCSVæ–‡ä»¶è¿›è¡Œå¢é‡æ›´æ–°ã€‚
   - [å¤‡ç”¨] ä»Akshareè·å–å®æ—¶æ•°æ®è¿›è¡Œæ›´æ–°ã€‚
2. åœ¨æ—¥çº¿æ•°æ®æ›´æ–°æˆåŠŸåï¼Œè‡ªåŠ¨å¯¹å‘¨çº¿(k_weekly)å’Œæœˆçº¿(k_monthly)æ•°æ®è¿›è¡Œå¢é‡æ›´æ–°ã€‚
3. è‡ªåŠ¨åˆ›å»ºæ‰€æœ‰éœ€è¦çš„æ•°æ®åº“è¡¨ã€‚
"""

import pandas as pd
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any
import akshare as ak
from pathlib import Path
import os

from .database_manager import DatabaseManager
from .timeframe_converter import TimeframeConverter
from core.utils.logger import get_logger
from core.utils.jqdata_converter import JQDataConverter

logger = get_logger("data_management.data_updater")


class DataUpdater:
    """
    ä¸€ä¸ªå®Œæ•´çš„æ—¥çº¿æ•°æ®å¤„ç†ç®¡é“ï¼Œæ”¯æŒä»èšå®½CSVæˆ–Akshareæ›´æ–°ï¼Œå¹¶è‡ªåŠ¨è½¬æ¢å‘¨çº¿/æœˆçº¿ã€‚
    ä¼˜å…ˆçº§ï¼šèšå®½æ•°æ® > Akshareæ•°æ®
    """
    def __init__(self, db_manager: DatabaseManager, jqdata_csv_path=None, jqdata_converted_path=None, akshare_cache_path=None):
        self.db_manager = db_manager
        self.jqdata_csv_path = jqdata_csv_path or "databases/daily_update_last.csv"
        self.jqdata_converted_path = jqdata_converted_path or "databases/daily_update_converted.csv"
        self.akshare_cache_path = akshare_cache_path or "databases/akshare_daily.csv"
        self.jqdata_converter = JQDataConverter()
        self.all_stock_codes = self._get_all_stock_codes()

    def _get_all_stock_codes(self):
        """ä»æ•°æ®åº“è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç """
        try:
            # ä½¿ç”¨ DatabaseManager è·å–è‚¡ç¥¨åˆ—è¡¨
            stock_codes = self.db_manager.get_stock_list("k_daily")
            logger.info(f"ä»æ•°æ®åº“æˆåŠŸè·å– {len(stock_codes)} ä¸ªè‚¡ç¥¨ä»£ç ã€‚")
            return set(stock_codes)
        except Exception as e:
            logger.error(f"ä»æ•°æ®åº“è·å–è‚¡ç¥¨ä»£ç å¤±è´¥: {e}")
            return set()

    # --- æ ¸å¿ƒåŠŸèƒ½1: ä»èšå®½æ•°æ®æ›´æ–° ---
    def update_from_jqdata(self):
        """[é¦–é€‰] ä»èšå®½CSVæ–‡ä»¶å¢é‡æ›´æ–°æ—¥çº¿æ•°æ®"""
        logger.info(f"--- æ¨¡å¼1: å°è¯•ä»èšå®½æ•°æ®æ–‡ä»¶ '{self.jqdata_csv_path}' æ›´æ–° ---")
        if not os.path.exists(self.jqdata_csv_path):
            logger.warning(f"èšå®½CSVæ–‡ä»¶ä¸å­˜åœ¨: {self.jqdata_csv_path}")
            return False, None

        try:
            # æ­¥éª¤1: è½¬æ¢èšå®½æ•°æ®æ ¼å¼
            logger.info("æ­£åœ¨è½¬æ¢èšå®½æ•°æ®æ ¼å¼...")
            success, quality = self.jqdata_converter.convert_and_validate(
                self.jqdata_csv_path, 
                self.jqdata_converted_path
            )
            
            if not success:
                logger.error(f"èšå®½æ•°æ®è½¬æ¢å¤±è´¥: {quality}")
                return False, None
            
            logger.info(f"èšå®½æ•°æ®è½¬æ¢æˆåŠŸ: {quality['total_records']} æ¡è®°å½•")
            
            # æ­¥éª¤2: è¯»å–è½¬æ¢åçš„æ•°æ®
            df = pd.read_csv(self.jqdata_converted_path)
            
            # æ•°æ®æ¸…æ´—å’Œæ ¼å¼åŒ–
            required_cols = ['stock_code', 'date', 'open', 'high', 'low', 'close', 'volume']
            if not all(col in df.columns for col in required_cols):
                logger.error(f"è½¬æ¢åçš„CSVæ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—ã€‚éœ€è¦: {required_cols}, å®é™…: {df.columns.tolist()}")
                return False, None

            df.rename(columns={'date': 'trade_date'}, inplace=True)
            df['stock_code'] = df['stock_code'].astype(str).str.zfill(6)
            df['trade_date'] = pd.to_datetime(df['trade_date']).dt.strftime('%Y-%m-%d')
            df.dropna(inplace=True)
            
            # åªä¿ç•™æ•°æ®åº“ä¸­å­˜åœ¨çš„è‚¡ç¥¨ä»£ç 
            df = df[df['stock_code'].isin(self.all_stock_codes)]
            if df.empty:
                logger.warning("è½¬æ¢åçš„èšå®½æ•°æ®ä¸­æ²¡æœ‰éœ€è¦æ›´æ–°çš„æœ‰æ•ˆè‚¡ç¥¨æ•°æ®ã€‚")
                return True, None # è®¤ä¸ºæˆåŠŸï¼Œä½†ä¸è§¦å‘å‘¨æœŸè½¬æ¢

            # ä½¿ç”¨ DatabaseManager ä¿å­˜æ•°æ®ï¼ˆä½¿ç”¨ replace ç­–ç•¥å¤„ç†å†²çªï¼‰
            success = self.db_manager.save_stock_data(df, "k_daily", conflict_resolution="replace")
            if success:
                min_date = df['trade_date'].min()
                logger.info(f"ğŸ‰ æˆåŠŸä»èšå®½æ•°æ®æ›´æ–°äº† {len(df)} æ¡æ—¥çº¿æ•°æ®ã€‚")
                return True, min_date
            else:
                logger.error("èšå®½æ•°æ®æ›´æ–°å¤±è´¥")
                return False, None

        except Exception as e:
            logger.error(f"ä»èšå®½æ•°æ®æ›´æ–°æ—¶å‡ºé”™: {e}")
            return False, None

    # --- æ ¸å¿ƒåŠŸèƒ½2: ä»Akshareæ›´æ–° ---
    def update_from_akshare(self):
        """[å¤‡ç”¨] ä»Akshareè·å–æ•°æ®å¹¶æ›´æ–°æ—¥çº¿"""
        logger.info("--- æ¨¡å¼2: å°è¯•ä» Akshare æ›´æ–° ---")
        try:
            logger.info("å¼€å§‹ä»akshareè·å–å½“æ—¥å®æ—¶è‚¡ç¥¨æ•°æ®...")
            stock_df = ak.stock_zh_a_spot_em()
            
            # éªŒè¯Akshareè¿”å›çš„å­—æ®µ
            required_akshare_cols = ['ä»£ç ', 'ä»Šå¼€', 'æœ€é«˜', 'æœ€ä½', 'æœ€æ–°ä»·', 'æˆäº¤é‡']
            missing_cols = [col for col in required_akshare_cols if col not in stock_df.columns]
            if missing_cols:
                logger.error(f"Akshareè¿”å›æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_cols}")
                logger.info(f"å®é™…å­—æ®µ: {stock_df.columns.tolist()}")
                return False, None
            
            # æ•°æ®æ˜ å°„å’Œæ¸…æ´—
            today = datetime.now().strftime('%Y-%m-%d')
            df = pd.DataFrame({
                'stock_code': stock_df['ä»£ç '],
                'trade_date': today,
                'open': stock_df['ä»Šå¼€'], 'high': stock_df['æœ€é«˜'], 'low': stock_df['æœ€ä½'],
                'close': stock_df['æœ€æ–°ä»·'], 'volume': stock_df['æˆäº¤é‡'] * 100
            })
            df.dropna(inplace=True)
            df = df[df['stock_code'].isin(self.all_stock_codes)]

            if df.empty:
                logger.warning("Akshareæ²¡æœ‰è¿”å›éœ€è¦æ›´æ–°çš„æœ‰æ•ˆè‚¡ç¥¨æ•°æ®ã€‚")
                return True, None

            # ä½¿ç”¨ DatabaseManager ä¿å­˜æ•°æ®ï¼ˆä½¿ç”¨ replace ç­–ç•¥å¤„ç†å†²çªï¼‰
            success = self.db_manager.save_stock_data(df, "k_daily", conflict_resolution="replace")
            if success:
                logger.info(f"ğŸ‰ æˆåŠŸä»Akshareæ›´æ–°äº† {len(df)} æ¡æ—¥çº¿æ•°æ®ã€‚")
                return True, today
            else:
                logger.error("Akshareæ•°æ®æ›´æ–°å¤±è´¥")
                return False, None

        except Exception as e:
            logger.error(f"ä»Akshareæ›´æ–°æ—¶å‡ºé”™: {e}")
            return False, None

    # --- æ ¸å¿ƒåŠŸèƒ½3: å‘¨æœŸæ•°æ®è½¬æ¢ ---
    def _update_resampled_data(self, start_date):
        """åœ¨æ—¥çº¿æ›´æ–°åï¼Œå¢é‡æ›´æ–°å‘¨çº¿å’Œæœˆçº¿æ•°æ®"""
        if start_date is None:
            logger.info("æ²¡æœ‰æ–°çš„æ—¥çº¿æ•°æ®ï¼Œè·³è¿‡å‘¨æœŸè½¬æ¢ã€‚")
            return

        logger.info("--- å¼€å§‹å¢é‡æ›´æ–°å‘¨çº¿å’Œæœˆçº¿æ•°æ® ---")
        
        # åªæ›´æ–°å‘¨çº¿æ•°æ®ï¼Œæœˆçº¿æ•°æ®å·²ç»å®Œæ•´
        self._resample_and_update('k_weekly', 'W-FRI', start_date)
        
        # æ£€æŸ¥æœˆçº¿æ•°æ®æ˜¯å¦éœ€è¦æ›´æ–°
        logger.info("æ£€æŸ¥æœˆçº¿æ•°æ®çŠ¶æ€...")
        try:
            # è·å–æœ€æ–°çš„æœˆçº¿æ•°æ®æ—¥æœŸ
            latest_monthly = self.db_manager.get_latest_data_date('k_monthly')
            if latest_monthly:
                logger.info(f"æœˆçº¿æ•°æ®æœ€æ–°æ—¥æœŸ: {latest_monthly}")
                # å¦‚æœæœˆçº¿æ•°æ®å·²ç»æ˜¯æœ€æ–°çš„ï¼Œè·³è¿‡è½¬æ¢
                if latest_monthly >= start_date:
                    logger.info("æœˆçº¿æ•°æ®å·²ç»æ˜¯æœ€æ–°çš„ï¼Œè·³è¿‡æœˆçº¿è½¬æ¢ã€‚")
                    return
                else:
                    logger.info("æœˆçº¿æ•°æ®éœ€è¦æ›´æ–°ï¼Œå¼€å§‹è½¬æ¢...")
                    self._resample_and_update('k_monthly', 'M', start_date)
            else:
                logger.info("æ²¡æœ‰æ‰¾åˆ°æœˆçº¿æ•°æ®ï¼Œå¼€å§‹è½¬æ¢...")
                self._resample_and_update('k_monthly', 'M', start_date)
        except Exception as e:
            logger.warning(f"æ£€æŸ¥æœˆçº¿æ•°æ®çŠ¶æ€å¤±è´¥: {e}ï¼Œè·³è¿‡æœˆçº¿è½¬æ¢ã€‚")

    def _resample_and_update(self, table_name, period_code, start_date):
        """é€šç”¨é‡é‡‡æ ·å’Œæ›´æ–°é€»è¾‘ - æœ€ç»ˆä¿®å¤ç‰ˆæœ¬"""
        try:
            from sqlalchemy import text
            
            # ç¡®å®šé‡è®¡ç®—çš„çœŸæ­£èµ·å§‹ç‚¹ï¼ˆå‘¨åˆæˆ–æœˆåˆï¼‰
            start_dt = pd.to_datetime(start_date)
            if period_code == 'W-FRI':
                recalc_start = (start_dt - pd.to_timedelta(start_dt.weekday(), unit='d')).strftime('%Y-%m-%d')
            else: # æœˆçº¿ ('M' or 'ME')
                recalc_start = start_dt.strftime('%Y-%m-01')

            logger.info(f"ä¸º '{table_name}' è¡¨é‡è®¡ç®—è‡ª {recalc_start} ä»¥æ¥çš„æ•°æ®...")

            # [æ ¸å¿ƒä¿®æ­£] æ¢å¤ä¸ºåŸå§‹çš„ã€æ›´ç¨³å®šçš„æ•°æ®åŠ è½½æ–¹å¼
            with self.db_manager.engine.connect() as conn:
                query = text("SELECT * FROM k_daily WHERE trade_date >= :recalc_start")
                result = conn.execute(query, {"recalc_start": recalc_start})
                daily_df = pd.DataFrame(result.fetchall(), columns=result.keys())
            
            if daily_df.empty:
                logger.info(f"åœ¨ {recalc_start} ä¹‹åæ²¡æœ‰æ—¥çº¿æ•°æ®ï¼Œè·³è¿‡ {table_name} æ›´æ–°ã€‚")
                return
                
            # æ‰§è¡Œå‘¨æœŸè½¬æ¢
            daily_df['trade_date'] = pd.to_datetime(daily_df['trade_date'])
            daily_df = daily_df.set_index('trade_date')
            
            # ä¿®å¤ 'M' çš„ FutureWarning
            resample_code = 'ME' if period_code == 'M' else period_code
            
            agg_rules = {'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last', 'volume': 'sum'}
            period_df = daily_df.groupby('stock_code').resample(resample_code).agg(agg_rules)
            period_df.dropna(inplace=True)
            period_df.reset_index(inplace=True)
            period_df['trade_date'] = period_df['trade_date'].dt.strftime('%Y-%m-%d')
            
            if period_df.empty:
                logger.warning(f"æ²¡æœ‰ç”Ÿæˆ {resample_code} æ•°æ®")
                return

            # ä½¿ç”¨ engine.begin() æ¥ç®¡ç†äº‹åŠ¡ï¼Œè‡ªåŠ¨æäº¤æˆ–å›æ»š
            with self.db_manager.engine.begin() as conn:
                # å…ˆåˆ é™¤æ—§æ•°æ®
                delete_query = text(f"DELETE FROM {table_name} WHERE trade_date >= :recalc_start")
                result = conn.execute(delete_query, {"recalc_start": recalc_start})
                logger.info(f"ä» {table_name} åˆ é™¤äº† {result.rowcount} æ¡æ—§æ•°æ®ã€‚")

            # ä½¿ç”¨æ‚¨å°è£…å¥½çš„ DatabaseManager ä¿å­˜æ–°æ•°æ®
            success = self.db_manager.save_stock_data(period_df, table_name, conflict_resolution="replace")
            if success:
                logger.info(f"âœ… æˆåŠŸæ›´æ–°äº† {len(period_df)} æ¡æ•°æ®åˆ° {table_name} è¡¨ã€‚")
            else:
                logger.error(f"ä¿å­˜æ•°æ®åˆ° {table_name} è¡¨å¤±è´¥")
            
        except Exception as e:
            logger.error(f"æ›´æ–° {table_name} è¡¨æ—¶å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")

    # --- ä¸»æµç¨‹ ---
    def run(self):
        """æ‰§è¡Œå®Œæ•´çš„æ•°æ®æ›´æ–°æµç¨‹"""
        logger.info("=============================================")
        logger.info("=== å¼€å§‹æ‰§è¡Œæ—¥çº¿æ•°æ®æ›´æ–°æµç¨‹ ===")
        logger.info("=== ä¼˜å…ˆçº§: èšå®½æ•°æ® > Akshareæ•°æ® ===")
        logger.info("=============================================")
        
        try:
            # æ­¥éª¤1: ä¼˜å…ˆå°è¯•ä»èšå®½æ•°æ®æ›´æ–°
            success, start_date = self.update_from_jqdata()

            # æ­¥éª¤2: å¦‚æœèšå®½æ•°æ®æ›´æ–°å¤±è´¥æˆ–æœªæ‰§è¡Œï¼Œåˆ™å›é€€åˆ°Akshare
            if not success:
                logger.warning("èšå®½æ•°æ®æ›´æ–°å¤±è´¥æˆ–æœªæ‰§è¡Œï¼Œå›é€€åˆ°Akshareæ›´æ–°æ¨¡å¼...")
                success, start_date = self.update_from_akshare()
            
            # æ­¥éª¤3: å¦‚æœæ—¥çº¿æ›´æ–°æˆåŠŸï¼Œåˆ™è§¦å‘å‘¨æœŸæ•°æ®è½¬æ¢
            if success:
                logger.info("æ—¥çº¿æ•°æ®æ›´æ–°æˆåŠŸï¼Œå¼€å§‹æ›´æ–°å‘¨çº¿å’Œæœˆçº¿...")
                self._update_resampled_data(start_date)
                logger.info("ğŸ‰ æ‰€æœ‰æ›´æ–°æµç¨‹æ‰§è¡Œå®Œæ¯•ï¼")
            else:
                logger.error("âŒ æ‰€æœ‰æ—¥çº¿æ›´æ–°æ–¹å¼å‡å¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
                
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æµç¨‹æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
            logger.error("å»ºè®®æ£€æŸ¥æ•°æ®åº“è¿æ¥å’Œæ•°æ®å®Œæ•´æ€§")
    
    # --- æ•°æ®éªŒè¯ ---
    def check_recent_data(self, stock_code='000029', days=5):
        """æŸ¥è¯¢æŒ‡å®šè‚¡ç¥¨æœ€è¿‘å‡ æ—¥çš„è¡Œæƒ…æ•°æ®ä»¥ä¾›éªŒè¯"""
        logger.info(f"\nğŸ” éªŒè¯è‚¡ç¥¨ {stock_code} æœ€è¿‘ {days} æ—¥çš„æ•°æ®...")
        
        # ä¸ºä¸åŒå‘¨æœŸè®¾ç½®ä¸åŒçš„æŸ¥è¯¢ç­–ç•¥
        table_configs = {
            'k_daily': {'limit': days, 'desc': f'æœ€è¿‘{days}æ—¥'},
            'k_weekly': {'limit': days, 'desc': f'æœ€è¿‘{days}å‘¨'},  # å‘¨çº¿è·å–æœ€è¿‘Næ¡è®°å½•
            'k_monthly': {'limit': days, 'desc': f'æœ€è¿‘{days}ä¸ªæœˆ'}  # æœˆçº¿è·å–æœ€è¿‘Næ¡è®°å½•
        }
        
        for table, config in table_configs.items():
            try:
                if table == 'k_daily':
                    # æ—¥çº¿æ•°æ®ä½¿ç”¨æ—¥æœŸèŒƒå›´æŸ¥è¯¢
                    end_date = datetime.now().strftime('%Y-%m-%d')
                    start_date = (datetime.now() - timedelta(days=config['limit'])).strftime('%Y-%m-%d')
                    df = self.db_manager.get_stock_data(stock_code, start_date, end_date, table)
                else:
                    # å‘¨çº¿å’Œæœˆçº¿æ•°æ®ä½¿ç”¨LIMITæŸ¥è¯¢ï¼Œè·å–æœ€æ–°çš„Næ¡è®°å½•
                    df = self.db_manager.get_latest_stock_data(stock_code, table, config['limit'])
                
                logger.info(f"--- {table} è¡¨æ•°æ® ({config['desc']}) ---")
                if df.empty:
                    logger.info("æœªæ‰¾åˆ°æ•°æ®ã€‚")
                else:
                    print(df.to_string(index=False))
                    logger.info(f"æˆåŠŸè·å– {len(df)} æ¡ {stock_code} æ•°æ®")
            except Exception as e:
                 logger.error(f"æŸ¥è¯¢ {table} è¡¨å¤±è´¥: {e}")
