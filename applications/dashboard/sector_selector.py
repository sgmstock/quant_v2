#ä»¥å‰çš„xuangu_bankuai.py
import streamlit as st
import sqlite3
import pandas as pd
import os
import sys
from typing import List, Dict, Set, Optional
import logging
from datetime import datetime, date
from tqdm import tqdm
import plotly.express as px
import plotly.graph_objects as go

# å¯¼å…¥v2é¡¹ç›®çš„æ¨¡å—
from core.utils.indicators import zhibiao
from core.technical_analyzer.technical_analyzer import TechnicalAnalyzer
from data_management.database_manager import DatabaseManager
from applications.sector_screener import get_changxian_zf_bankuai, get_boduan_bias_bankuai, get_boduan_zf_bankuai

# æ³¨æ„ï¼šéœ€è¦å¯¼å…¥TechnicalAnalyzerç±»ï¼Œè¯·æ ¹æ®å®é™…è·¯å¾„è°ƒæ•´

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é¡µé¢é…ç½®å’Œæ—¥æœŸé€‰æ‹©å°†åœ¨main()å‡½æ•°ä¸­å¤„ç†

# æ·»åŠ ç”³ä¸‡è¡Œä¸šæ•°æ®è·å–å‡½æ•°
@st.cache_data
def get_sw_hierarchy_data():
    """è·å–ç”³ä¸‡è¡Œä¸šå±‚æ¬¡ç»“æ„æ•°æ®"""
    try:
        db_manager = DatabaseManager()
        query = "SELECT DISTINCT l1_code, l1_name, l2_code, l2_name, l3_code, l3_name FROM sw_cfg_hierarchy WHERE l1_name IS NOT NULL AND l1_name != '' ORDER BY l1_code, l2_code, l3_code"
        df = db_manager.execute_query(query)
        
        # ç¡®ä¿æ‰€æœ‰ä»£ç éƒ½æœ‰æ­£ç¡®çš„åç¼€æ ¼å¼ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
        for col in ['l1_code', 'l2_code', 'l3_code']:
            if col in df.columns:
                # å¦‚æœä»£ç æ²¡æœ‰åç¼€ï¼Œæ·»åŠ .SIç”¨äºæ˜¾ç¤º
                df[col] = df[col].apply(lambda x: f"{x}.SI" if not str(x).endswith(('.SI', '.ZS')) else str(x))
        
        return df
    except Exception as e:
        st.error(f"è·å–ç”³ä¸‡è¡Œä¸šæ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()

def get_index_code_from_sw_code(sw_code):
    """å°†ç”³ä¸‡ä»£ç è½¬æ¢ä¸ºæŒ‡æ•°ä»£ç """
    # å¦‚æœå·²ç»æ˜¯.ZSåç¼€ï¼Œç›´æ¥è¿”å›
    if sw_code.endswith('.ZS'):
        return sw_code
    # å¦‚æœæ˜¯.SIåç¼€ï¼Œåˆ™æ›¿æ¢ä¸º.ZS
    elif sw_code.endswith('.SI'):
        return sw_code.replace('.SI', '.ZS')
    # å¦åˆ™ç›´æ¥æ·»åŠ .ZS
    else:
        return f"{sw_code}.ZS"

def get_refined_sectors_for_standard_index(standard_index_code):
    """è·å–æ ‡å‡†æ¿å—çš„æ‰€æœ‰ç»†åŒ–æ¿å—"""
    try:
        # æå–å‰6ä½æ•°å­—ä½œä¸ºåŸºç¡€ä»£ç 
        base_code = standard_index_code[:6]
        
        # å®šä¹‰ç»†åŒ–æ¿å—åç¼€
        refined_suffixes = ['CQ', 'DBJ', 'DSZ', 'GBJ', 'GQ', 'XSZ']
        
        # ç”Ÿæˆç»†åŒ–æ¿å—ä»£ç åˆ—è¡¨
        refined_codes = []
        for suffix in refined_suffixes:
            refined_codes.append(f"{base_code}.{suffix}")
        
        # æ£€æŸ¥å“ªäº›ç»†åŒ–æ¿å—åœ¨æ•°æ®åº“ä¸­å­˜åœ¨
        db_manager = DatabaseManager()
        existing_codes = []
        for code in refined_codes:
            query = f'SELECT COUNT(*) as count FROM index_k_daily WHERE index_code = "{code}"'
            result = db_manager.execute_query(query)
            count = result.iloc[0]['count']
            if count > 0:
                existing_codes.append(code)
        
        # åˆ›å»ºDataFrame
        if existing_codes:
            df = pd.DataFrame({
                'index_code': existing_codes,
                'index_name': [f"{code} (ç»†åŒ–æ¿å—)" for code in existing_codes]
            })
        else:
            df = pd.DataFrame()
        
        return df
    except Exception as e:
        st.error(f"è·å–ç»†åŒ–æ¿å—å¤±è´¥: {e}")
        return pd.DataFrame()

def get_refined_sector_suffix_meaning():
    """è·å–ç»†åŒ–æ¿å—åç¼€çš„å«ä¹‰"""
    return {
        'DSZ': 'å¤§å¸‚å€¼æŒ‡æ•°',
        'XSZ': 'å°å¸‚å€¼æŒ‡æ•°', 
        'GBJ': 'é«˜ä»·è‚¡æŒ‡æ•°',
        'DBJ': 'ä½ä»·è‚¡æŒ‡æ•°',
        'GQ': 'å›½ä¼è‚¡æŒ‡æ•°',
        'CQ': 'è¶…å¼ºè‚¡æŒ‡æ•°'
    }

def prepare_technical_data_for_refined_sector_analysis(index_code, date):
    """
    ä¸ºç»†åŒ–æ¿å—æŒ‡æ•°å‡†å¤‡æŠ€æœ¯åˆ†ææ‰€éœ€çš„æ‰€æœ‰å‘¨æœŸæ•°æ®
    è¿”å›ä¸æ ‡å‡†æ¿å—ç›¸åŒæ ¼å¼çš„æ•°æ®å­—å…¸
    
    Args:
        index_code: ç»†åŒ–æ¿å—æŒ‡æ•°ä»£ç 
        date: åˆ†ææ—¥æœŸ
    
    Returns:
        dict: åŒ…å«monthlyã€weeklyã€dailyæ•°æ®çš„å­—å…¸ï¼Œå¦‚æœæ•°æ®ä¸è¶³åˆ™è¿”å›None
    """
    try:
        # è·å–æ—¥çº¿æ•°æ®
        df_daily = get_daily_data_for_sector_backtest(index_code, date)
        if df_daily.empty or len(df_daily) < 20:
            return None
        
        # è·å–å‘¨çº¿æ•°æ®
        df_weekly = get_weekly_data_for_sector_backtest(index_code, date)
        if df_weekly.empty:
            return None
        
        # è·å–æœˆçº¿æ•°æ®
        df_monthly = get_monthly_data_for_sector_backtest(index_code, date)
        if df_monthly.empty:
            return None
        
        # è¿”å›åŸå§‹æ•°æ®ï¼ŒTechnicalAnalyzerä¼šåœ¨å†…éƒ¨è°ƒç”¨zhibiaoå‡½æ•°
        return {
            'monthly': df_monthly,
            'weekly': df_weekly,
            'daily': df_daily
        }
        
    except Exception as e:
        print(f"ä¸ºç»†åŒ–æ¿å— {index_code} å‡†å¤‡æŠ€æœ¯æ•°æ®å¤±è´¥: {e}")
        return None


def get_refined_sector_technical_scores(refined_codes, date):
    """è·å–ç»†åŒ–æ¿å—çš„æŠ€æœ¯è¯„åˆ†ï¼ˆåŸºäºindex_k_dailyè¡¨ï¼‰"""
    try:
        results = [] 
        
        for index_code in tqdm(refined_codes, desc="æ­£åœ¨åˆ†æç»†åŒ–æ¿å—æŠ€æœ¯çŠ¶æ€"):
            # å‡†å¤‡æŠ€æœ¯æ•°æ®
            data_dict = prepare_technical_data_for_refined_sector_analysis(index_code, date)
            
            if not data_dict:
                print(f"è­¦å‘Šï¼šæœªèƒ½ä¸ºç»†åŒ–æ¿å— {index_code} å‡†å¤‡æŠ€æœ¯æ•°æ®ï¼Œå·²è·³è¿‡ã€‚")
                continue
            
            # åˆ›å»ºåˆ†æå™¨å®ä¾‹
            analyzer = TechnicalAnalyzer(data_dict)
            
            # è®¡ç®—å„é¡¹æŠ€æœ¯æŒ‡æ ‡å¾—åˆ†
            results.append({
                'index_code': index_code,
                'zj_jjdi': analyzer.zj_jjdi(),
                'zj_di': analyzer.zj_di(),
                'zjdtg': analyzer.zjdtg(),
                'zjdtz': analyzer.zjdtz(),
                'cx_jjdi': analyzer.cx_jjdi(),
                'cx_di': analyzer.cx_di(),
                'cxdtg': analyzer.cxdtg(),
                'cxdtz': analyzer.cxdtz(),
                'cx_ding_tzz': analyzer.cx_ding_tzz(),
                'cx_ding_baoliang': analyzer.cx_ding_baoliang(),
                'ccx_jjdi': analyzer.ccx_jjdi(),
                'ccx_di': analyzer.ccx_di(),
                'ccxdtg': analyzer.ccxdtg(),
                'ccxdtz': analyzer.ccxdtz(),
            })
        
        if not results:
            return pd.DataFrame()
        
        df = pd.DataFrame(results)
        
        # åˆå¹¶æ¿å—æŒ‡æ•°åç§°ä¿¡æ¯
        db_manager = DatabaseManager()
        index_info = db_manager.execute_query("SELECT DISTINCT index_code, index_name FROM index_k_daily WHERE index_code LIKE '801%' OR index_code LIKE '850%' OR index_code LIKE '100%' OR index_code LIKE '851%' OR index_code LIKE '852%' OR index_code LIKE '857%' OR index_code LIKE '858%' OR index_code LIKE '859%'")
        
        df = df.merge(index_info, on='index_code', how='left')
        
        # è°ƒæ•´åˆ—é¡ºåº
        cols = ['index_code', 'index_name'] + [col for col in df.columns if col not in ['index_code', 'index_name']]
        df = df[cols]
        
        return df
        
    except Exception as e:
        st.error(f"è·å–ç»†åŒ–æ¿å—æŠ€æœ¯è¯„åˆ†å¤±è´¥: {e}")
        return pd.DataFrame()


def get_refined_sector_basic_analysis(refined_codes, date):
    """è·å–ç»†åŒ–æ¿å—çš„åŸºæœ¬åˆ†ææ•°æ®ï¼ˆåŸºäºindex_k_dailyè¡¨ï¼‰"""
    try:
        db_manager = DatabaseManager()
        
        # è·å–æœ€æ–°ä»·æ ¼æ•°æ®
        latest_data = []
        for code in refined_codes:
            query = f'''
            SELECT index_code, index_name, close, volume, trade_date
            FROM index_k_daily 
            WHERE index_code = "{code}" 
            ORDER BY trade_date DESC 
            LIMIT 1
            '''
            result = db_manager.execute_query(query)
            if not result.empty:
                latest_data.append(result.iloc[0])
        
        if not latest_data:
            return pd.DataFrame()
        
        df = pd.DataFrame(latest_data)
        
        # æ·»åŠ åŸºæœ¬åˆ†ææŒ‡æ ‡
        df['price_change'] = 0  # ç®€åŒ–å¤„ç†ï¼Œå®é™…å¯ä»¥è®¡ç®—æ¶¨è·Œå¹…
        df['volume_ratio'] = 1.0  # ç®€åŒ–å¤„ç†ï¼Œå®é™…å¯ä»¥è®¡ç®—æˆäº¤é‡æ¯”
        
        # æ·»åŠ åç¼€å«ä¹‰
        suffix_meanings = get_refined_sector_suffix_meaning()
        df['suffix'] = df['index_code'].str.split('.').str[-1]
        df['suffix_meaning'] = df['suffix'].map(suffix_meanings)
        
        return df
        
    except Exception as e:
        st.error(f"è·å–ç»†åŒ–æ¿å—åŸºæœ¬åˆ†ææ•°æ®å¤±è´¥: {e}")
        return pd.DataFrame()


def get_refined_sector_zhuli_scores(refined_codes):
    """è·å–ç»†åŒ–æ¿å—çš„ä¸»åŠ›è¯„åˆ†ï¼ˆåŸºäºå¸‚å€¼åˆ†æï¼‰"""
    try:
        # è¯»å–å¸‚å€¼åˆ†ææ•°æ®
        excel_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', '..', 'databases', 'sector_market_cap_analysis.xlsx')
        excel_path = os.path.abspath(excel_path)
        df_market_cap = pd.read_excel(excel_path)
        
        # å°†index_codeåç¼€ä».SIæ”¹ä¸º.ZSï¼ˆæ ‡å‡†æ¿å—ï¼‰
        df_market_cap['index_code'] = df_market_cap['index_code'].str.replace('.SI', '.ZS')
        
        # ä¸ºç»†åŒ–æ¿å—è®¡ç®—ä¸»åŠ›è¯„åˆ†
        zhuli_scores = []
        for code in refined_codes:
            # æå–åŸºç¡€ä»£ç ï¼ˆå‰6ä½ï¼‰
            base_code = code[:6]
            
            # æŸ¥æ‰¾å¯¹åº”çš„æ ‡å‡†æŒ‡æ•°ï¼ˆç²¾ç¡®åŒ¹é…å‰6ä½ï¼‰
            standard_codes = df_market_cap[df_market_cap['index_code'].str.startswith(base_code + '.')]
            
            if not standard_codes.empty:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ ‡å‡†æŒ‡æ•°æ•°æ®
                standard_data = standard_codes.iloc[0]
                zhuli_score = 0
                zhuli_score += (standard_data['è¶…å¼º'] > 0.8) * 1
                zhuli_score += (standard_data['è¶…è¶…å¼º'] > 0.6) * 1
                zhuli_score += (standard_data['å¤§é«˜'] > 0.7) * 1
                zhuli_score += (standard_data['å›½ä¼'] > 0.7) * 1
            else:
                zhuli_score = 0
            
            zhuli_scores.append({
                'index_code': code,
                'zhuli_score': zhuli_score
            })
        
        return pd.DataFrame(zhuli_scores)
        
    except Exception as e:
        st.error(f"è·å–ç»†åŒ–æ¿å—ä¸»åŠ›è¯„åˆ†å¤±è´¥: {e}")
        return pd.DataFrame()


def calculate_refined_sector_comprehensive_scores(refined_codes, date):
    """
    è®¡ç®—ç»†åŒ–æ¿å—çš„ç»¼åˆå¾—åˆ†ï¼ˆæŠ€æœ¯å¾—åˆ†+ä¸»åŠ›å¾—åˆ†+ATRå¾—åˆ†ï¼‰
    
    Args:
        refined_codes: ç»†åŒ–æ¿å—ä»£ç åˆ—è¡¨
        date: åˆ†ææ—¥æœŸ
    
    Returns:
        DataFrameåŒ…å«æ¯ä¸ªç»†åŒ–æ¿å—çš„ä»£ç ã€åç§°å’Œå„é¡¹å¾—åˆ†ï¼ŒæŒ‰total_scoreé™åºæ’åˆ—
        åŒ…å«å­—æ®µï¼šindex_code, index_name, zj_score, cx_score, ccx_score, 
                technical_score, zhuli_score, atr_score, total_score
    """
    try:
        # è·å–æŠ€æœ¯è¯„åˆ†æ•°æ®
        df_technical = get_refined_sector_technical_scores(refined_codes, date)
        
        if df_technical.empty:
            return pd.DataFrame()
        
        # è®¡ç®—ä¸­çº§æŠ€æœ¯æŒ‡æ ‡å¾—åˆ†
        zj_scores = pd.DataFrame()
        zj_scores['index_code'] = df_technical['index_code']
        zj_scores['zjjjdi_score'] = df_technical['zj_jjdi'] * 1.0
        zj_scores['zjdi_score'] = df_technical['zj_di'] * 2.0
        zj_scores['zjdtg_score'] = df_technical['zjdtg'] * 2.0
        zj_scores['zjdtz_score'] = df_technical['zjdtz'] * 0
        # å–æœ€å¤§å€¼
        zj_scores['zj_score'] = zj_scores[['zjjjdi_score','zjdi_score', 'zjdtg_score', 'zjdtz_score']].max(axis=1)
        
        # è®¡ç®—é•¿çº¿æŠ€æœ¯æŒ‡æ ‡å¾—åˆ†
        cx_scores = pd.DataFrame()
        cx_scores['index_code'] = df_technical['index_code']
        cx_scores['cx_jjdi_score'] = df_technical['cx_jjdi'] * 0.5
        cx_scores['cx_di_score'] = df_technical['cx_di'] * 2.5
        cx_scores['cxdtg_score'] = df_technical['cxdtg'] * 4
        cx_scores['cxdtz_score'] = df_technical['cxdtz'] * 0.5
        cx_scores['cx_ding_tzz_score'] = df_technical['cx_ding_tzz'] * -1
        cx_scores['cx_ding_baoliang_score'] = df_technical['cx_ding_baoliang'] * -1
        
        # å–æœ€å¤§å€¼
        cx_scores['cx_final_score'] = cx_scores[['cx_jjdi_score','cx_di_score', 'cxdtg_score', 'cxdtz_score']].max(axis=1)
        cx_scores['cx_score'] = cx_scores['cx_final_score'] + cx_scores['cx_ding_baoliang_score'] + cx_scores['cx_ding_tzz_score']
        
        # è®¡ç®—è¶…é•¿çº¿æŠ€æœ¯æŒ‡æ ‡å¾—åˆ†
        ccx_scores = pd.DataFrame()
        ccx_scores['index_code'] = df_technical['index_code']
        ccx_scores['ccx_jjdi_score'] = df_technical['ccx_jjdi'] * 1
        ccx_scores['ccx_di_score'] = df_technical['ccx_di'] * 3
        ccx_scores['ccxdtg_score'] = df_technical['ccxdtg'] * 3
        ccx_scores['ccxdtz_score'] = df_technical['ccxdtz'] * 1
        
        # å–æœ€å¤§å€¼
        ccx_scores['ccx_final_score'] = ccx_scores[['ccx_jjdi_score', 'ccx_di_score', 'ccxdtg_score', 'ccxdtz_score']].max(axis=1)
        ccx_scores['ccx_score'] = ccx_scores['ccx_final_score']
        
        # åˆå¹¶æŠ€æœ¯å¾—åˆ†
        technical_scores = zj_scores[['index_code', 'zj_score']].merge(
            cx_scores[['index_code', 'cx_score']], on='index_code', how='left'
        ).merge(
            ccx_scores[['index_code', 'ccx_score']], on='index_code', how='left'
        )
        
        # è®¡ç®—æŠ€æœ¯æ€»åˆ†
        technical_scores['technical_score'] = technical_scores['zj_score'] + technical_scores['cx_score'] + technical_scores['ccx_score']
        
        # è·å–ä¸»åŠ›å¾—åˆ†
        df_zhuli = get_refined_sector_zhuli_scores(refined_codes)
        
        if df_zhuli.empty:
            # å¦‚æœä¸»åŠ›è¯„åˆ†ä¸ºç©ºï¼Œåˆ›å»ºé»˜è®¤çš„ä¸»åŠ›å¾—åˆ†
            zhuli_scores = pd.DataFrame({
                'index_code': df_technical['index_code'],
                'zhuli_score': 0
            })
        else:
            zhuli_scores = df_zhuli[['index_code', 'zhuli_score']]
        
        # è·å–ATRè¯„åˆ†
        atr_scores_dict = get_atr_score(refined_codes, date)
        atr_scores = pd.DataFrame({
            'index_code': list(atr_scores_dict.keys()),
            'atr_score': list(atr_scores_dict.values())
        })
        
        # åˆå¹¶æŠ€æœ¯å¾—åˆ†ã€ä¸»åŠ›å¾—åˆ†å’ŒATRå¾—åˆ†
        final_scores = technical_scores.merge(zhuli_scores, on='index_code', how='left')
        final_scores = final_scores.merge(atr_scores, on='index_code', how='left')
        
        # å¡«å……ç¼ºå¤±çš„ä¸»åŠ›å¾—åˆ†å’ŒATRå¾—åˆ†ä¸º0
        final_scores['zhuli_score'] = final_scores['zhuli_score'].fillna(0)
        final_scores['atr_score'] = final_scores['atr_score'].fillna(0)
        
        # åˆå¹¶æ¿å—æŒ‡æ•°åŸºæœ¬ä¿¡æ¯
        db_manager = DatabaseManager()
        
        # é¦–å…ˆä»index_k_dailyè¡¨è·å–åç§°ä¿¡æ¯ï¼ˆåŒ…å«è‡ªå®šä¹‰æŒ‡æ•°ä»£ç ï¼‰
        index_info = db_manager.execute_query("SELECT DISTINCT index_code, index_name FROM index_k_daily WHERE index_code LIKE '801%' OR index_code LIKE '850%' OR index_code LIKE '100%' OR index_code LIKE '851%' OR index_code LIKE '852%' OR index_code LIKE '857%' OR index_code LIKE '858%' OR index_code LIKE '859%'")
        
        # ç„¶åä»xinfenleiè¡¨è·å–åç§°ä¿¡æ¯ï¼ˆç”¨äºè¡¥å……ç¼ºå¤±çš„åç§°ï¼‰
        xinfenlei_info = db_manager.execute_query("SELECT DISTINCT sw_xin_code as index_code, sw_name as index_name FROM xinfenlei")
        
        
        # åˆå¹¶ä¸¤ä¸ªæ•°æ®æºçš„åç§°ä¿¡æ¯
        combined_info = pd.concat([index_info, xinfenlei_info]).drop_duplicates(subset=['index_code'], keep='first')
        
        final_scores = final_scores.merge(combined_info, on='index_code', how='left')
        
        # è®¡ç®—ç»¼åˆæ€»åˆ†
        final_scores['total_score'] = final_scores['technical_score'] + final_scores['zhuli_score'] + final_scores['atr_score']
        
        # è°ƒæ•´åˆ—é¡ºåº
        final_scores = final_scores[['index_code', 'index_name', 'zj_score', 'cx_score', 'ccx_score', 'technical_score', 'zhuli_score', 'atr_score', 'total_score']]
        
        # æŒ‰total_scoreé™åºæ’åº
        final_scores = final_scores.sort_values(by='total_score', ascending=False)
        
        return final_scores
        
    except Exception as e:
        st.error(f"è®¡ç®—ç»†åŒ–æ¿å—ç»¼åˆå¾—åˆ†å¤±è´¥: {e}")
        return pd.DataFrame()

def display_refined_sector_analysis(standard_index_code, date):
    """æ˜¾ç¤ºæ ‡å‡†æ¿å—åŠå…¶ç»†åŒ–æ¿å—çš„è¯„åˆ†åˆ†æ"""
    st.subheader(f"ğŸ” ç»†åŒ–æ¿å—åˆ†æ: {standard_index_code}")
    
    # è·å–ç»†åŒ–æ¿å—æ•°æ®
    refined_sectors = get_refined_sectors_for_standard_index(standard_index_code)
    
    if refined_sectors.empty:
        st.warning(f"æœªæ‰¾åˆ° {standard_index_code} çš„ç»†åŒ–æ¿å—æ•°æ®")
        return
    
    # æ˜¾ç¤ºç»†åŒ–æ¿å—åˆ—è¡¨
    st.write("**ğŸ“‹ ç»†åŒ–æ¿å—åˆ—è¡¨:**")
    suffix_meanings = get_refined_sector_suffix_meaning()
    
    for _, row in refined_sectors.iterrows():
        index_code = row['index_code']
        index_name = row['index_name']
        suffix = index_code.split('.')[-1]
        meaning = suffix_meanings.get(suffix, 'æœªçŸ¥ç±»å‹')
        
        st.write(f"â€¢ **{index_code}**: {index_name} ({meaning})")
    
    # è·å–ç»†åŒ–æ¿å—çš„æŒ‡æ•°ä»£ç åˆ—è¡¨
    refined_codes = refined_sectors['index_code'].tolist()
    
    # æ£€æŸ¥å“ªäº›ç»†åŒ–æ¿å—åœ¨æ•°æ®åº“ä¸­å­˜åœ¨
    conn = DatabaseManager()
    existing_refined_codes = []
    missing_refined_codes = []
    
    for code in refined_codes:
        query = f'SELECT COUNT(*) as count FROM index_k_daily WHERE index_code = "{code}"'
        result = db_manager.execute_query(query)
        count = result.iloc[0]['count']
        
        if count > 0:
            existing_refined_codes.append(code)
        else:
            missing_refined_codes.append(code)
    
    conn.close()
    
    if missing_refined_codes:
        st.warning(f"âš ï¸ **ä»¥ä¸‹ç»†åŒ–æ¿å—åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨**: {', '.join(missing_refined_codes)}")
    
    if not existing_refined_codes:
        st.error("âŒ **æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ç»†åŒ–æ¿å—æ•°æ®**")
        return
    
    st.info(f"âœ… **å°†åˆ†æ {len(existing_refined_codes)} ä¸ªæœ‰æ•ˆç»†åŒ–æ¿å—**")
    
    # å¯¹ç»†åŒ–æ¿å—è¿›è¡Œç»¼åˆè¯„åˆ†åˆ†æ
    try:
        st.write(f"ğŸ”„ **æ­£åœ¨è·å–ç»†åŒ–æ¿å—åˆ†ææ•°æ®**: {len(existing_refined_codes)} ä¸ªæ¿å—")
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆæŠ€æœ¯å¾—åˆ†+ä¸»åŠ›å¾—åˆ†ï¼‰
        st.write("ğŸ”„ **æ­£åœ¨è®¡ç®—ç»†åŒ–æ¿å—ç»¼åˆå¾—åˆ†**...")
        comprehensive_scores = calculate_refined_sector_comprehensive_scores(existing_refined_codes, date)
        
        if comprehensive_scores.empty:
            st.error("âŒ **æ— æ³•è·å–ç»†åŒ–æ¿å—ç»¼åˆè¯„åˆ†æ•°æ®**")
            return
        
        st.write(f"âœ… ç»†åŒ–æ¿å—ç»¼åˆè¯„åˆ†è®¡ç®—å®Œæˆ: {comprehensive_scores.shape}")
        
        # æ˜¾ç¤ºç»¼åˆè¯„åˆ†è¡¨æ ¼
        st.write("**ğŸ“Š ç»†åŒ–æ¿å—ç»¼åˆè¯„åˆ†è¯¦æƒ…:**")
        st.dataframe(
            comprehensive_scores[['index_code', 'index_name', 'zj_score', 'cx_score', 'ccx_score', 'technical_score', 'zhuli_score', 'total_score']],
            use_container_width=True
        )
        
        # æ˜¾ç¤ºè¯„åˆ†ç»Ÿè®¡
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å¹³å‡æŠ€æœ¯å¾—åˆ†", f"{comprehensive_scores['technical_score'].mean():.2f}")
        with col2:
            st.metric("å¹³å‡ä¸»åŠ›å¾—åˆ†", f"{comprehensive_scores['zhuli_score'].mean():.2f}")
        with col3:
            st.metric("å¹³å‡ç»¼åˆå¾—åˆ†", f"{comprehensive_scores['total_score'].mean():.2f}")
        
        # æ˜¾ç¤ºå¾—åˆ†åˆ†å¸ƒå›¾
        st.write("**ğŸ“ˆ ç»†åŒ–æ¿å—å¾—åˆ†åˆ†å¸ƒ:**")
        import plotly.express as px
        
        # ç»¼åˆå¾—åˆ†æ’åå‰10
        fig1 = px.bar(
            comprehensive_scores.head(10), 
            x='index_name', 
            y='total_score',
            title=f"{standard_index_code} ç»†åŒ–æ¿å—ç»¼åˆå¾—åˆ†æ’åå‰10",
            labels={'total_score': 'ç»¼åˆå¾—åˆ†', 'index_name': 'æ¿å—åç§°'}
        )
        fig1.update_layout(xaxis_tickangle=45)
        st.plotly_chart(fig1, use_container_width=True)
        
        # æŠ€æœ¯å¾—åˆ† vs ä¸»åŠ›å¾—åˆ†æ•£ç‚¹å›¾
        fig2 = px.scatter(
            comprehensive_scores,
            x='technical_score',
            y='zhuli_score',
            hover_data=['index_code', 'index_name', 'total_score'],
            title='æŠ€æœ¯å¾—åˆ† vs ä¸»åŠ›å¾—åˆ†',
            labels={'technical_score': 'æŠ€æœ¯å¾—åˆ†', 'zhuli_score': 'ä¸»åŠ›å¾—åˆ†'}
        )
        st.plotly_chart(fig2, use_container_width=True)
        
        # è·å–ç»†åŒ–æ¿å—åŸºæœ¬åˆ†ææ•°æ®
        df_basic = get_refined_sector_basic_analysis(existing_refined_codes, date)
        
        if not df_basic.empty:
            st.write(f"âœ… ç»†åŒ–æ¿å—åŸºæœ¬åˆ†æå®Œæˆ: {df_basic.shape}")
            
            # æ˜¾ç¤ºç»†åŒ–æ¿å—åŸºæœ¬ä¿¡æ¯è¡¨æ ¼
            st.write("**ğŸ“Š ç»†åŒ–æ¿å—åŸºæœ¬ä¿¡æ¯:**")
            st.dataframe(
                df_basic[['index_code', 'index_name', 'suffix_meaning', 'close', 'volume', 'trade_date']],
                use_container_width=True
            )
            
            # æ˜¾ç¤ºä»·æ ¼åˆ†å¸ƒå›¾è¡¨
            st.write("**ğŸ“ˆ ç»†åŒ–æ¿å—ä»·æ ¼åˆ†å¸ƒ:**")
            df_sorted = df_basic.sort_values('close', ascending=False)
            
            fig = px.bar(
                df_sorted, 
                x='index_name', 
                y='close',
                title=f'{standard_index_code} ç»†åŒ–æ¿å—ä»·æ ¼å¯¹æ¯”',
                labels={'close': 'æ”¶ç›˜ä»·', 'index_name': 'æ¿å—åç§°'}
            )
            fig.update_layout(xaxis_tickangle=45)
            st.plotly_chart(fig, use_container_width=True)
            
            # æ˜¾ç¤ºæˆäº¤é‡åˆ†å¸ƒå›¾è¡¨
            st.write("**ğŸ“Š ç»†åŒ–æ¿å—æˆäº¤é‡åˆ†å¸ƒ:**")
            fig_volume = px.bar(
                df_sorted, 
                x='index_name', 
                y='volume',
                title=f'{standard_index_code} ç»†åŒ–æ¿å—æˆäº¤é‡å¯¹æ¯”',
                labels={'volume': 'æˆäº¤é‡', 'index_name': 'æ¿å—åç§°'}
            )
            fig_volume.update_layout(xaxis_tickangle=45)
            st.plotly_chart(fig_volume, use_container_width=True)
            
            # æ˜¾ç¤ºä»·æ ¼å’Œæˆäº¤é‡çš„æ•£ç‚¹å›¾
            st.write("**ğŸ“ˆ ç»†åŒ–æ¿å—ä»·æ ¼ä¸æˆäº¤é‡å…³ç³»:**")
            fig_scatter = px.scatter(
                df_sorted,
                x='close',
                y='volume',
                hover_data=['index_code', 'index_name', 'suffix_meaning'],
                title='ä»·æ ¼ vs æˆäº¤é‡',
                labels={'close': 'æ”¶ç›˜ä»·', 'volume': 'æˆäº¤é‡'}
            )
            st.plotly_chart(fig_scatter, use_container_width=True)
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            st.write("**ğŸ“Š ç»†åŒ–æ¿å—ç»Ÿè®¡ä¿¡æ¯:**")
            st.metric("å¹³å‡ä»·æ ¼", f"{df_sorted['close'].mean():.2f}")
            st.metric("æœ€é«˜ä»·æ ¼", f"{df_sorted['close'].max():.2f}")
            st.metric("å¹³å‡æˆäº¤é‡", f"{df_sorted['volume'].mean():.0f}")
            st.metric("æœ€é«˜æˆäº¤é‡", f"{df_sorted['volume'].max():.0f}")
        
        # æ˜¾ç¤ºè¯´æ˜ä¿¡æ¯
        st.info("ğŸ’¡ **è¯´æ˜**: ç»†åŒ–æ¿å—æ•°æ®æ¥æºäº `index_k_daily` è¡¨ï¼ŒåŒ…å«å¤§å¸‚å€¼ã€å°å¸‚å€¼ã€é«˜ä»·è‚¡ã€ä½ä»·è‚¡ã€å›½ä¼è‚¡ã€è¶…å¼ºè‚¡ç­‰ä¸åŒç±»å‹çš„ç»†åˆ†æŒ‡æ•°ã€‚ç°åœ¨ä½¿ç”¨ä¸æ ‡å‡†æ¿å—ç›¸åŒçš„è¯„åˆ†ä½“ç³»ï¼ŒåŒ…æ‹¬æŠ€æœ¯è¯„åˆ†å’Œä¸»åŠ›è¯„åˆ†ã€‚")
    
    except Exception as e:
        st.error(f"ç»†åŒ–æ¿å—åˆ†æå¤±è´¥: {e}")
        import traceback
        st.text(traceback.format_exc())

def display_sector_scores(sector_codes, date):
    """æ˜¾ç¤ºæ¿å—è¯„åˆ†è¯¦æƒ…"""
    if not sector_codes:
        st.warning("æ²¡æœ‰é€‰æ‹©ä»»ä½•æ¿å—")
        return
    
    st.subheader("ğŸ“Š æ¿å—è¯„åˆ†è¯¦æƒ…")
    
    # æ˜¾ç¤ºå®é™…ä½¿ç”¨çš„æŒ‡æ•°ä»£ç 
    st.info(f"ğŸ” **åˆ†æçš„æ¿å—æŒ‡æ•°ä»£ç **: {', '.join(sector_codes)}")
    
    # å…ˆæ£€æŸ¥å“ªäº›æŒ‡æ•°ä»£ç åœ¨æ•°æ®åº“ä¸­å­˜åœ¨
    conn = DatabaseManager()
    existing_codes = []
    missing_codes = []
    
    for code in sector_codes:
        query = f'SELECT COUNT(*) as count FROM index_k_daily WHERE index_code = "{code}"'
        result = db_manager.execute_query(query)
        count = result.iloc[0]['count']
        
        if count > 0:
            existing_codes.append(code)
        else:
            missing_codes.append(code)
    
    conn.close()
    
    if missing_codes:
        st.warning(f"âš ï¸ **ä»¥ä¸‹æŒ‡æ•°ä»£ç åœ¨æ•°æ®åº“ä¸­ä¸å­˜åœ¨**: {', '.join(missing_codes)}")
        st.info("ğŸ’¡ **è¯´æ˜**: è¿™äº›ä»£ç å¯èƒ½æ˜¯ç»†åŒ–æ¿å—ä»£ç ï¼ˆå¦‚801050.CQã€801050.DBJç­‰ï¼‰ï¼Œå°†åªæ˜¾ç¤ºä¸»åŠ›è¯„åˆ†ï¼Œä¸è¿›è¡ŒæŠ€æœ¯åˆ†æ")
    
    if not existing_codes:
        st.error("âŒ **æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„æŒ‡æ•°ä»£ç **")
        return
    
    st.info(f"âœ… **å°†åˆ†æ {len(existing_codes)} ä¸ªæœ‰æ•ˆæŒ‡æ•°ä»£ç **")
    
    # è·å–æŠ€æœ¯åˆ†ææ•°æ®
    try:
        st.write(f"ğŸ”„ **æ­£åœ¨è·å–æŠ€æœ¯åˆ†ææ•°æ®**: {len(existing_codes)} ä¸ªæ¿å—æŒ‡æ•°")
        
        df_zj = get_jishu_zj(existing_codes, date)
        st.write(f"âœ… ä¸­çº§æŠ€æœ¯åˆ†æå®Œæˆ: {df_zj.shape}")
        
        df_cx = get_jishu_cx(existing_codes, date)
        st.write(f"âœ… é•¿çº¿æŠ€æœ¯åˆ†æå®Œæˆ: {df_cx.shape}")
        
        df_ccx = get_jishu_ccx(existing_codes, date)
        st.write(f"âœ… è¶…é•¿çº¿æŠ€æœ¯åˆ†æå®Œæˆ: {df_ccx.shape}")
        
        # è®¡ç®—ç»¼åˆå¾—åˆ†
        st.write("ğŸ”„ **æ­£åœ¨è®¡ç®—ç»¼åˆå¾—åˆ†**...")
        comprehensive_scores = calculate_comprehensive_scores(df_zj, df_cx, df_ccx, date)
        
        if comprehensive_scores.empty:
            st.error("âŒ **æ— æ³•è·å–è¯„åˆ†æ•°æ®**ï¼šæŠ€æœ¯åˆ†ææ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç»¼åˆå¾—åˆ†")
            return
        
        st.write(f"âœ… ç»¼åˆå¾—åˆ†è®¡ç®—å®Œæˆ: {comprehensive_scores.shape}")
        
        # æ˜¾ç¤ºè¯„åˆ†è¡¨æ ¼
        st.dataframe(
            comprehensive_scores[['index_code', 'index_name', 'zj_score', 'cx_score', 'ccx_score', 'technical_score', 'zhuli_score', 'atr_score', 'total_score']],
            use_container_width=True
        )
        
        # æ˜¾ç¤ºè¯„åˆ†ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("å¹³å‡æŠ€æœ¯å¾—åˆ†", f"{comprehensive_scores['technical_score'].mean():.2f}")
        with col2:
            st.metric("å¹³å‡ä¸»åŠ›å¾—åˆ†", f"{comprehensive_scores['zhuli_score'].mean():.2f}")
        with col3:
            st.metric("å¹³å‡ATRå¾—åˆ†", f"{comprehensive_scores['atr_score'].mean():.2f}")
        with col4:
            st.metric("å¹³å‡ç»¼åˆå¾—åˆ†", f"{comprehensive_scores['total_score'].mean():.2f}")
        
        # æ˜¾ç¤ºå¾—åˆ†åˆ†å¸ƒå›¾ - ä¸Šä¸‹å¸ƒå±€
        st.subheader("ğŸ“ˆ å¾—åˆ†åˆ†å¸ƒ")
        
        import plotly.express as px
        fig1 = px.bar(
            comprehensive_scores.head(10), 
            x='index_name', 
            y='total_score',
            title="ç»¼åˆå¾—åˆ†æ’åå‰10"
        )
        fig1.update_layout(xaxis_tickangle=45)
        st.plotly_chart(fig1, use_container_width=True)
        
        fig2 = px.scatter(
            comprehensive_scores, 
            x='technical_score', 
            y='zhuli_score',
            hover_data=['index_name', 'total_score'],
            title="æŠ€æœ¯å¾—åˆ† vs ä¸»åŠ›å¾—åˆ†"
        )
        st.plotly_chart(fig2, use_container_width=True)
            
        # ä¸ºç¼ºå¤±çš„æ¿å—ä»£ç æ˜¾ç¤ºä¸»åŠ›è¯„åˆ†
        if missing_codes:
            st.subheader("ğŸ’° ç»†åŒ–æ¿å—ä¸»åŠ›è¯„åˆ†")
            st.write(f"ğŸ”„ **æ­£åœ¨è·å–ç»†åŒ–æ¿å—ä¸»åŠ›è¯„åˆ†**: {len(missing_codes)} ä¸ªæ¿å—")
            
            # è·å–ä¸»åŠ›è¯„åˆ†
            zhuli_df = zhuli_score()
            missing_scores = []
            
            for code in missing_codes:
                # æŸ¥æ‰¾å¯¹åº”çš„ä¸»åŠ›è¯„åˆ†
                matching_scores = zhuli_df[zhuli_df['index_code'] == code]
                if not matching_scores.empty:
                    score = matching_scores.iloc[0]['å¾—åˆ†']
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•åŸºç¡€ä»£ç åŒ¹é…
                    base_code = code[:6]
                    base_matching = zhuli_df[zhuli_df['index_code'].str.startswith(base_code + '.')]
                    if not base_matching.empty:
                        score = base_matching.iloc[0]['å¾—åˆ†']
                    else:
                        score = 0
                
                missing_scores.append({
                    'index_code': code,
                    'index_name': f"{code} (ç»†åŒ–æ¿å—)",
                    'zhuli_score': score,
                    'technical_score': 0,
                    'total_score': score
                })
            
            if missing_scores:
                missing_df = pd.DataFrame(missing_scores)
                st.dataframe(
                    missing_df[['index_code', 'index_name', 'zhuli_score', 'total_score']],
                    use_container_width=True
                )
                
                st.metric("å¹³å‡ä¸»åŠ›å¾—åˆ†", f"{missing_df['zhuli_score'].mean():.2f}")
        
    except Exception as e:
        st.error(f"è·å–è¯„åˆ†æ•°æ®å¤±è´¥: {e}")

def display_sw_sector_hierarchy():
    """æ˜¾ç¤ºç”³ä¸‡è¡Œä¸šå±‚æ¬¡ç»“æ„å¹¶æ”¯æŒäº¤äº’é€‰æ‹©"""
    st.subheader("ğŸ¢ ç”³ä¸‡è¡Œä¸šæ¿å—é€‰æ‹©")
    
    # æ·»åŠ è¯´æ˜
    st.info("ğŸ’¡ **è¯´æ˜**: ç•Œé¢æ˜¾ç¤ºçš„æ˜¯ç”³ä¸‡è¡Œä¸šä»£ç (.SIåç¼€)ï¼Œç‚¹å‡»è¯„åˆ†æ—¶ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºæ¿å—æŒ‡æ•°ä»£ç (.ZSåç¼€)è¿›è¡Œåˆ†æ")
    
    # è·å–åˆ†ææ—¥æœŸ
    analysis_date = st.session_state.get('analysis_date', '2024-01-01')
    
    # è·å–ç”³ä¸‡è¡Œä¸šæ•°æ®
    sw_data = get_sw_hierarchy_data()
    if sw_data.empty:
        st.error("æ— æ³•è·å–ç”³ä¸‡è¡Œä¸šæ•°æ®")
        return
    
    # åˆ›å»ºå±‚æ¬¡ç»“æ„å±•ç¤º
    l1_sectors = sw_data[['l1_code', 'l1_name']].drop_duplicates().sort_values('l1_code')
    
    # é€‰æ‹©ä¸€çº§è¡Œä¸š
    selected_l1 = st.selectbox(
        "é€‰æ‹©ä¸€çº§è¡Œä¸š:",
        options=l1_sectors['l1_code'].tolist(),
        format_func=lambda x: f"{x} - {l1_sectors[l1_sectors['l1_code']==x]['l1_name'].iloc[0]}"
    )
    
    if selected_l1:
        # è·å–è¯¥ä¸€çº§è¡Œä¸šä¸‹çš„äºŒçº§è¡Œä¸š
        l2_sectors = sw_data[sw_data['l1_code'] == selected_l1][['l2_code', 'l2_name']].drop_duplicates().sort_values('l2_code')
        
        if not l2_sectors.empty:
            st.write(f"**{l1_sectors[l1_sectors['l1_code']==selected_l1]['l1_name'].iloc[0]}** ä¸‹çš„äºŒçº§è¡Œä¸š:")
            
            # æ˜¾ç¤ºäºŒçº§è¡Œä¸šåˆ—è¡¨
            for _, row in l2_sectors.iterrows():
                with st.expander(f"{row['l2_code']} - {row['l2_name']}"):
                    # è·å–è¯¥äºŒçº§è¡Œä¸šä¸‹çš„ä¸‰çº§è¡Œä¸š
                    l3_sectors = sw_data[sw_data['l2_code'] == row['l2_code']][['l3_code', 'l3_name']].drop_duplicates().sort_values('l3_code')
                    
                    if not l3_sectors.empty:
                        st.write("ä¸‰çº§è¡Œä¸š:")
                        for _, l3_row in l3_sectors.iterrows():
                            st.write(f"  â€¢ {l3_row['l3_code']} - {l3_row['l3_name']}")
                    
                    # æ·»åŠ è¯„åˆ†æŒ‰é’® - ä¸Šä¸‹å¸ƒå±€
                    if st.button(f"æŸ¥çœ‹ {row['l2_name']} è¯„åˆ†", key=f"btn_{row['l2_code']}"):
                        # è·å–è¯¥äºŒçº§è¡Œä¸šåŠå…¶å­è¡Œä¸šçš„æ‰€æœ‰æŒ‡æ•°ä»£ç 
                        sector_codes = []
                        
                        # æ·»åŠ äºŒçº§è¡Œä¸šæœ¬èº«
                        index_code = get_index_code_from_sw_code(row['l2_code'])
                        sector_codes.append(index_code)
                        
                        # æ·»åŠ ä¸‰çº§è¡Œä¸š
                        for _, l3_row in l3_sectors.iterrows():
                            index_code = get_index_code_from_sw_code(l3_row['l3_code'])
                            sector_codes.append(index_code)
                        
                        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
                        st.write(f"ğŸ” **è°ƒè¯•ä¿¡æ¯**: è½¬æ¢åçš„æŒ‡æ•°ä»£ç : {sector_codes}")
                        
                        # æ˜¾ç¤ºè¯„åˆ†
                        display_sector_scores(sector_codes, analysis_date)
                    
                    if st.button(f"æŸ¥çœ‹ {row['l2_name']} ç»†åŒ–æ¿å—", key=f"refined_{row['l2_code']}"):
                        # è·å–äºŒçº§è¡Œä¸šçš„æŒ‡æ•°ä»£ç å¹¶æ˜¾ç¤ºç»†åŒ–æ¿å—åˆ†æ
                        index_code = get_index_code_from_sw_code(row['l2_code'])
                        display_refined_sector_analysis(index_code, analysis_date)
        
        # æ·»åŠ æŸ¥çœ‹æ•´ä¸ªä¸€çº§è¡Œä¸šè¯„åˆ†çš„æŒ‰é’® - ä¸Šä¸‹å¸ƒå±€
        if st.button(f"æŸ¥çœ‹æ•´ä¸ª {l1_sectors[l1_sectors['l1_code']==selected_l1]['l1_name'].iloc[0]} è¯„åˆ†", key=f"btn_l1_{selected_l1}"):
            # è·å–è¯¥ä¸€çº§è¡Œä¸šä¸‹æ‰€æœ‰æŒ‡æ•°ä»£ç 
            sector_codes = []
            for _, row in l2_sectors.iterrows():
                index_code = get_index_code_from_sw_code(row['l2_code'])
                sector_codes.append(index_code)
                
                # æ·»åŠ ä¸‰çº§è¡Œä¸š
                l3_sectors = sw_data[sw_data['l2_code'] == row['l2_code']][['l3_code', 'l3_name']].drop_duplicates()
                for _, l3_row in l3_sectors.iterrows():
                    index_code = get_index_code_from_sw_code(l3_row['l3_code'])
                    sector_codes.append(index_code)
            
            # æ˜¾ç¤ºè¯„åˆ†
            display_sector_scores(sector_codes, analysis_date)
        
        if st.button(f"æŸ¥çœ‹ {l1_sectors[l1_sectors['l1_code']==selected_l1]['l1_name'].iloc[0]} ç»†åŒ–æ¿å—", key=f"refined_l1_{selected_l1}"):
            # è·å–ä¸€çº§è¡Œä¸šçš„æŒ‡æ•°ä»£ç å¹¶æ˜¾ç¤ºç»†åŒ–æ¿å—åˆ†æ
            index_code = get_index_code_from_sw_code(selected_l1)
            display_refined_sector_analysis(index_code, analysis_date)

def load_index_daily_data(index_code: str) -> pd.DataFrame:
    """
    ä»æœ¬åœ°åŠ è½½æ¿å—æŒ‡æ•°çš„æ—¥çº¿è¡Œæƒ…æ•°æ®ã€‚
    """
    conn = DatabaseManager()
    df = db_manager.execute_query(f"SELECT * FROM index_k_daily WHERE index_code = '{index_code}'", conn)
    conn.close()
    return df

def load_index_weekly_data(index_code: str) -> pd.DataFrame:
    """
    ä»æœ¬åœ°åŠ è½½æ¿å—æŒ‡æ•°çš„å‘¨çº¿è¡Œæƒ…æ•°æ®ã€‚
    """
    conn = DatabaseManager()
    df = db_manager.execute_query(f"SELECT * FROM index_k_weekly WHERE index_code = '{index_code}'", conn)
    conn.close()
    return df

def load_index_monthly_data(index_code: str) -> pd.DataFrame:
    """
    ä»æœ¬åœ°åŠ è½½æ¿å—æŒ‡æ•°çš„æœˆçº¿è¡Œæƒ…æ•°æ®ã€‚
    """
    conn = DatabaseManager()
    df = db_manager.execute_query(f"SELECT * FROM index_k_monthly WHERE index_code = '{index_code}'", conn)
    conn.close()
    return df

#è®¾è®¡ä¸“é—¨ç”¨äºå›æµ‹ç”¨çš„è·å–æ¿å—æŒ‡æ•°çš„æ—¥çº¿è¡Œæƒ…æ•°æ®ï¼š
def get_daily_data_for_sector_backtest(index_code: str, current_date: str) -> pd.DataFrame:
    """
    ä¸ºç­–ç•¥æä¾›åœ¨ç‰¹å®šæ—¥æœŸæ‰€éœ€çš„æ•°æ®ã€‚
    åœ¨å›æµ‹æ¨¡å¼ä¸‹ï¼Œå®ƒåªä»æœ¬åœ°å¿«é€Ÿè¯»å–å’Œåˆ‡ç‰‡ï¼Œä¸è¿›è¡Œä»»ä½•æ›´æ–°æ“ä½œã€‚
    """
    # 1. ä»æœ¬åœ°åŠ è½½è¯¥è‚¡ç¥¨çš„ã€å…¨éƒ¨ã€‘å†å²æ•°æ®
    #    (ä¼˜åŒ–ï¼šå¯ä»¥åœ¨å›æµ‹å¼€å§‹æ—¶ä¸€æ¬¡æ€§åŠ è½½æ‰€æœ‰è‚¡ç¥¨åˆ°å†…å­˜)
    full_local_df = load_index_daily_data(index_code) 

    # 2. ä¸¥æ ¼æˆªå–æˆªè‡³ current_date çš„æ•°æ®ï¼Œé˜²æ­¢æœªæ¥å‡½æ•°
    # ç¡®ä¿ trade_date åˆ—æ˜¯ datetime ç±»å‹ï¼Œä½¿ç”¨æ›´å®‰å…¨çš„è§£ææ–¹å¼
    full_local_df['trade_date'] = pd.to_datetime(full_local_df['trade_date'], errors='coerce')
    # ç¡®ä¿ current_date æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    try:
        if isinstance(current_date, str):
            current_date_dt = pd.to_datetime(current_date, errors='coerce')
        else:
            current_date_dt = pd.to_datetime(current_date, errors='coerce')
        
        # æ£€æŸ¥æ—¥æœŸè½¬æ¢æ˜¯å¦æˆåŠŸ
        if pd.isna(current_date_dt):
            raise ValueError(f"æ— æ³•è§£ææ—¥æœŸ: {current_date}")
        
        df_snapshot = full_local_df[full_local_df['trade_date'] <= current_date_dt].copy()
    except Exception as e:
        print(f"æ—¥æœŸè½¬æ¢é”™è¯¯: {e}")
        # å¦‚æœæ—¥æœŸè½¬æ¢å¤±è´¥ï¼Œè¿”å›ç©ºDataFrame
        return pd.DataFrame()
    
    return df_snapshot


#è®¾è®¡ä¸“é—¨ç”¨äºå›æµ‹ç”¨çš„è·å–æ¿å—æŒ‡æ•°çš„å‘¨çº¿è¡Œæƒ…æ•°æ®ï¼š
def get_weekly_data_for_sector_backtest(index_code: str, current_date: str) -> pd.DataFrame:
    """
    ä¸ºç­–ç•¥æä¾›åœ¨ç‰¹å®šæ—¥æœŸæ‰€éœ€çš„æ•°æ®ã€‚
    åœ¨å›æµ‹æ¨¡å¼ä¸‹ï¼Œå®ƒåªä»æœ¬åœ°å¿«é€Ÿè¯»å–å’Œåˆ‡ç‰‡ï¼Œä¸è¿›è¡Œä»»ä½•æ›´æ–°æ“ä½œã€‚
    """
    full_local_df = load_index_weekly_data(index_code)
    full_local_df['trade_date'] = pd.to_datetime(full_local_df['trade_date'], errors='coerce')
    # ç¡®ä¿ current_date æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    try:
        if isinstance(current_date, str):
            current_date_dt = pd.to_datetime(current_date, errors='coerce')
        else:
            current_date_dt = pd.to_datetime(current_date, errors='coerce')
        
        # æ£€æŸ¥æ—¥æœŸè½¬æ¢æ˜¯å¦æˆåŠŸ
        if pd.isna(current_date_dt):
            raise ValueError(f"æ— æ³•è§£ææ—¥æœŸ: {current_date}")
        
        df_snapshot = full_local_df[full_local_df['trade_date'] <= current_date_dt].copy()
    except Exception as e:
        print(f"æ—¥æœŸè½¬æ¢é”™è¯¯: {e}")
        # å¦‚æœæ—¥æœŸè½¬æ¢å¤±è´¥ï¼Œè¿”å›ç©ºDataFrame
        return pd.DataFrame()

    return df_snapshot

def get_monthly_data_for_sector_backtest(index_code: str, current_date: str) -> pd.DataFrame:
    """
    ä¸ºç­–ç•¥æä¾›åœ¨ç‰¹å®šæ—¥æœŸæ‰€éœ€çš„æ•°æ®ã€‚
    åœ¨å›æµ‹æ¨¡å¼ä¸‹ï¼Œå®ƒåªä»æœ¬åœ°å¿«é€Ÿè¯»å–å’Œåˆ‡ç‰‡ï¼Œä¸è¿›è¡Œä»»ä½•æ›´æ–°æ“ä½œã€‚
    """
    full_local_df = load_index_monthly_data(index_code)
    full_local_df['trade_date'] = pd.to_datetime(full_local_df['trade_date'], errors='coerce')
    # ç¡®ä¿ current_date æ˜¯å­—ç¬¦ä¸²æ ¼å¼
    try:
        if isinstance(current_date, str):
            current_date_dt = pd.to_datetime(current_date, errors='coerce')
        else:
            current_date_dt = pd.to_datetime(current_date, errors='coerce')
        
        # æ£€æŸ¥æ—¥æœŸè½¬æ¢æ˜¯å¦æˆåŠŸ
        if pd.isna(current_date_dt):
            raise ValueError(f"æ— æ³•è§£ææ—¥æœŸ: {current_date}")
        
        df_snapshot = full_local_df[full_local_df['trade_date'] <= current_date_dt].copy()
    except Exception as e:
        print(f"æ—¥æœŸè½¬æ¢é”™è¯¯: {e}")
        # å¦‚æœæ—¥æœŸè½¬æ¢å¤±è´¥ï¼Œè¿”å›ç©ºDataFrame
        return pd.DataFrame()

    return df_snapshot

# #å¯¹è¡Œæƒ…ç”¨zhibiaoå‡½æ•°è®¡ç®—æŒ‡æ ‡
# def zhibiao(df: pd.DataFrame) -> pd.DataFrame:
#     """
#     å¯¹è¡Œæƒ…ç”¨zhibiaoå‡½æ•°è®¡ç®—æŒ‡æ ‡
#     """
#     return zhibiao(df)


#æ­¥éª¤1ï¼šåˆ›å»ºä¸€ä¸ªæ•°æ®å‡†å¤‡çš„è¾…åŠ©å‡½æ•°
#è¿™ä¸ªå‡½æ•°è´Ÿè´£ä¸ºå•ä¸ªæ¿å—æŒ‡æ•°å‡†å¤‡å¥½ æ‰€éœ€è¦çš„zhibiaoæ•°æ®å­—å…¸ã€‚
def prepare_technical_data_for_sector_analysis(index_code, date):
    """
    ä¸ºæ¿å—æŒ‡æ•°å‡†å¤‡æŠ€æœ¯åˆ†ææ‰€éœ€çš„æ‰€æœ‰å‘¨æœŸæ•°æ®
    
    Args:
        index_code: æ¿å—æŒ‡æ•°ä»£ç 
        date: åˆ†ææ—¥æœŸ
    
    Returns:
        dict: åŒ…å«monthlyã€weeklyã€dailyæ•°æ®çš„å­—å…¸ï¼Œå¦‚æœæ•°æ®ä¸è¶³åˆ™è¿”å›None
    """
    try:
        # è·å–æ—¥çº¿æ•°æ®
        df_daily = get_daily_data_for_sector_backtest(index_code, date)
        if df_daily.empty or len(df_daily) < 20:
            print(f"è­¦å‘Šï¼š{index_code} æ—¥çº¿æ•°æ®ä¸è¶³ï¼Œå·²è·³è¿‡")
            return None
        
        # è·å–å‘¨çº¿æ•°æ®
        df_weekly = get_weekly_data_for_sector_backtest(index_code, date)
        if df_weekly.empty:
            print(f"è­¦å‘Šï¼š{index_code} å‘¨çº¿æ•°æ®ä¸ºç©ºï¼Œå·²è·³è¿‡")
            return None
        
        # è·å–æœˆçº¿æ•°æ®
        df_monthly = get_monthly_data_for_sector_backtest(index_code, date)
        if df_monthly.empty:
            print(f"è­¦å‘Šï¼š{index_code} æœˆçº¿æ•°æ®ä¸ºç©ºï¼Œå·²è·³è¿‡")
            return None
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        df_M = zhibiao(df_monthly)
        df_w = zhibiao(df_weekly)
        df_d = zhibiao(df_daily)
        
        return {
            'monthly': df_M,
            'weekly': df_w,
            'daily': df_d
        }
        
    except Exception as e:
        print(f"ä¸ºæ¿å—æŒ‡æ•° {index_code} å‡†å¤‡æŠ€æœ¯æ•°æ®å¤±è´¥: {e}")
        return None

#æ­¥éª¤2ï¼šåˆ›å»ºä¸€ä¸ªåˆ†æå™¨å·¥å‚å‡½æ•°
def create_analyzer(index_code, date):
    """
    åˆ›å»ºä¸€ä¸ª TechnicalAnalyzer ç±»å®ä¾‹ã€‚
    """
    data_dict = prepare_technical_data_for_sector_analysis(index_code, date)
    if data_dict is None:
        return None
    return TechnicalAnalyzer(data_dict)


#æ­¥éª¤3ï¼šè·å–æ¿å—æŒ‡æ•°ä¸­çº§æŠ€æœ¯çŠ¶æ€
def get_jishu_zj(indexlist: list, date: str):
    """
    ä½¿ç”¨ TechnicalAnalyzer ç±»æ¥æ‰¹é‡è®¡ç®—æ¿å—æŒ‡æ•°çš„æŠ€æœ¯æŒ‡æ ‡ä¿¡å·ã€‚
    """
    results = []
    
    # éå†æ¿å—æŒ‡æ•°åˆ—è¡¨
    for index_code in tqdm(indexlist, desc="æ­£åœ¨åˆ†ææ¿å—æŒ‡æ•°"):
        # 1. ä¸ºå½“å‰æ¿å—æŒ‡æ•°å‡†å¤‡æ‰€éœ€çš„æ‰€æœ‰å‘¨æœŸæ•°æ®
        data_dict = prepare_technical_data_for_sector_analysis(index_code, date)
        
        # å¦‚æœæ•°æ®å‡†å¤‡å¤±è´¥ï¼ˆä¾‹å¦‚ï¼Œæ•°æ®ä¸è¶³ï¼‰ï¼Œåˆ™è·³è¿‡
        if not data_dict:
            print(f"è­¦å‘Šï¼šæœªèƒ½ä¸ºæ¿å—æŒ‡æ•° {index_code} å‡†å¤‡æ•°æ®ï¼Œå·²è·³è¿‡ã€‚")
            continue
            
        # 2. åˆ›å»ºåˆ†æå™¨å®ä¾‹ï¼Œæ•°æ®å’ŒæŒ‡æ ‡è®¡ç®—éƒ½åœ¨è¿™ä¸€æ­¥å®Œæˆ
        try:
            analyzer = TechnicalAnalyzer(data_dict)
        except Exception as e:
            print(f"è­¦å‘Šï¼šä¸ºæ¿å—æŒ‡æ•° {index_code} åˆ›å»ºåˆ†æå™¨å¤±è´¥: {e}ï¼Œå·²è·³è¿‡ã€‚")
            continue
        
        # 3. è°ƒç”¨åˆ†ææ–¹æ³•è·å–è¯„åˆ†
        results.append({
            'index_code': index_code,
            'zj_jjdi': analyzer.zj_jjdi(),
            'zj_di': analyzer.zj_di(),
            'zjdtg': analyzer.zjdtg(),
            'zjdtz': analyzer.zjdtz(),
        })
        
    # è½¬æ¢ä¸ºDataFrame
    if not results:
        return pd.DataFrame()
        
    df = pd.DataFrame(results)
    
    # åˆå¹¶æ¿å—æŒ‡æ•°åç§°ä¿¡æ¯
    conn = DatabaseManager()
    index_info = db_manager.execute_query("SELECT DISTINCT index_code, index_name FROM index_k_daily WHERE index_code LIKE '801%' OR index_code LIKE '850%' OR index_code LIKE '100%' OR index_code LIKE '851%' OR index_code LIKE '852%' OR index_code LIKE '857%' OR index_code LIKE '858%' OR index_code LIKE '859%'", conn)
    conn.close()
    
    df = df.merge(index_info, on='index_code', how='left')
    
    # è°ƒæ•´åˆ—é¡ºåº
    cols = ['index_code', 'index_name'] + [col for col in df.columns if col not in ['index_code', 'index_name']]
    df = df[cols]
    
    return df
#æ­¥éª¤4ï¼šè·å–æ¿å—æŒ‡æ•°é•¿çº¿æŠ€æœ¯çŠ¶æ€
def get_jishu_cx(indexlist: list, date: str):
    """
    è·å–æ¿å—æŒ‡æ•°é•¿çº¿æŠ€æœ¯çŠ¶æ€
    """
    results = []
    
    for index_code in tqdm(indexlist, desc="æ­£åœ¨åˆ†ææ¿å—æŒ‡æ•°"):
        # 1. ä¸ºå½“å‰æ¿å—æŒ‡æ•°å‡†å¤‡æ‰€éœ€çš„æ‰€æœ‰å‘¨æœŸæ•°æ®
        data_dict = prepare_technical_data_for_sector_analysis(index_code, date)
        
        # å¦‚æœæ•°æ®å‡†å¤‡å¤±è´¥ï¼ˆä¾‹å¦‚ï¼Œæ•°æ®ä¸è¶³ï¼‰ï¼Œåˆ™è·³è¿‡
        if not data_dict:
            print(f"è­¦å‘Šï¼šæœªèƒ½ä¸ºæ¿å—æŒ‡æ•° {index_code} å‡†å¤‡æ•°æ®ï¼Œå·²è·³è¿‡ã€‚")
            continue
            
        # 2. åˆ›å»ºåˆ†æå™¨å®ä¾‹ï¼Œæ•°æ®å’ŒæŒ‡æ ‡è®¡ç®—éƒ½åœ¨è¿™ä¸€æ­¥å®Œæˆ
        try:
            analyzer = TechnicalAnalyzer(data_dict)
        except Exception as e:
            print(f"è­¦å‘Šï¼šä¸ºæ¿å—æŒ‡æ•° {index_code} åˆ›å»ºåˆ†æå™¨å¤±è´¥: {e}ï¼Œå·²è·³è¿‡ã€‚")
            continue
            
        results.append({
            'index_code': index_code,
            'cx_jjdi': analyzer.cx_jjdi(),
            'cx_di': analyzer.cx_di(),
            'cxdtg': analyzer.cxdtg(),
            'cxdtz': analyzer.cxdtz(),
            'cx_ding_tzz': analyzer.cx_ding_tzz(),
            'cx_ding_baoliang': analyzer.cx_ding_baoliang(),
        })
    
    # è½¬æ¢ä¸ºDataFrame
    if not results:
        return pd.DataFrame()
        
    df = pd.DataFrame(results)
    
    # åˆå¹¶æ¿å—æŒ‡æ•°åç§°ä¿¡æ¯
    conn = DatabaseManager()
    index_info = db_manager.execute_query("SELECT DISTINCT index_code, index_name FROM index_k_daily WHERE index_code LIKE '801%' OR index_code LIKE '850%' OR index_code LIKE '100%' OR index_code LIKE '851%' OR index_code LIKE '852%' OR index_code LIKE '857%' OR index_code LIKE '858%' OR index_code LIKE '859%'", conn)
    conn.close()
    
    df = df.merge(index_info, on='index_code', how='left')
    
    # è°ƒæ•´åˆ—é¡ºåº
    cols = ['index_code', 'index_name'] + [col for col in df.columns if col not in ['index_code', 'index_name']]
    df = df[cols]
    
    return df


#æ­¥éª¤5ï¼šè·å–æ¿å—æŒ‡æ•°è¶…é•¿çº¿æŠ€æœ¯çŠ¶æ€
def get_jishu_ccx(indexlist: list, date: str):
    """
    è·å–æ¿å—æŒ‡æ•°è¶…é•¿çº¿æŠ€æœ¯çŠ¶æ€
    """
    results = []
    
    for index_code in tqdm(indexlist, desc="æ­£åœ¨åˆ†ææ¿å—æŒ‡æ•°"):
        # 1. ä¸ºå½“å‰æ¿å—æŒ‡æ•°å‡†å¤‡æ‰€éœ€çš„æ‰€æœ‰å‘¨æœŸæ•°æ®
        data_dict = prepare_technical_data_for_sector_analysis(index_code, date)
        
        # å¦‚æœæ•°æ®å‡†å¤‡å¤±è´¥ï¼ˆä¾‹å¦‚ï¼Œæ•°æ®ä¸è¶³ï¼‰ï¼Œåˆ™è·³è¿‡
        if not data_dict:
            print(f"è­¦å‘Šï¼šæœªèƒ½ä¸ºæ¿å—æŒ‡æ•° {index_code} å‡†å¤‡æ•°æ®ï¼Œå·²è·³è¿‡ã€‚")
            continue
            
        # 2. åˆ›å»ºåˆ†æå™¨å®ä¾‹ï¼Œæ•°æ®å’ŒæŒ‡æ ‡è®¡ç®—éƒ½åœ¨è¿™ä¸€æ­¥å®Œæˆ
        try:
            analyzer = TechnicalAnalyzer(data_dict)
        except Exception as e:
            print(f"è­¦å‘Šï¼šä¸ºæ¿å—æŒ‡æ•° {index_code} åˆ›å»ºåˆ†æå™¨å¤±è´¥: {e}ï¼Œå·²è·³è¿‡ã€‚")
            continue
            
        results.append({
            'index_code': index_code,
            'ccx_jjdi': analyzer.ccx_jjdi(),
            'ccx_di': analyzer.ccx_di(),
            'ccxdtg': analyzer.ccxdtg(),
            'ccxdtz': analyzer.ccxdtz(),
        })
    
    # è½¬æ¢ä¸ºDataFrame
    if not results:
        return pd.DataFrame()
        
    df = pd.DataFrame(results)
    
    # åˆå¹¶æ¿å—æŒ‡æ•°åç§°ä¿¡æ¯
    conn = DatabaseManager()
    index_info = db_manager.execute_query("SELECT DISTINCT index_code, index_name FROM index_k_daily WHERE index_code LIKE '801%' OR index_code LIKE '850%' OR index_code LIKE '100%' OR index_code LIKE '851%' OR index_code LIKE '852%' OR index_code LIKE '857%' OR index_code LIKE '858%' OR index_code LIKE '859%'", conn)
    conn.close()
    
    df = df.merge(index_info, on='index_code', how='left')
    
    # è°ƒæ•´åˆ—é¡ºåº
    cols = ['index_code', 'index_name'] + [col for col in df.columns if col not in ['index_code', 'index_name']]
    df = df[cols]
    
    return df


#æ­¥éª¤6ï¼šè®¡ç®—æ¿å—æŒ‡æ•°ç»¼åˆå¾—åˆ†ï¼ˆæŠ€æœ¯å¾—åˆ†+ä¸»åŠ›å¾—åˆ†ï¼‰
def calculate_comprehensive_scores(df_zj, df_cx, df_ccx, date=None):
    """
    æ ¹æ®æŠ€æœ¯æŒ‡æ ‡ã€ä¸»åŠ›åˆ†æå’ŒATRåˆ†æè®¡ç®—æ¿å—æŒ‡æ•°ç»¼åˆå¾—åˆ†
    
    Args:
        df_zj: ä¸­çº§æŠ€æœ¯æŒ‡æ ‡DataFrame
        df_cx: é•¿çº¿æŠ€æœ¯æŒ‡æ ‡DataFrame
        df_ccx: è¶…é•¿çº¿æŠ€æœ¯æŒ‡æ ‡DataFrame
        date: åˆ†ææ—¥æœŸï¼Œç”¨äºè®¡ç®—ATRè¯„åˆ†
    
    Returns:
        DataFrameåŒ…å«æ¯ä¸ªæ¿å—æŒ‡æ•°çš„ä»£ç ã€åç§°å’Œå„é¡¹å¾—åˆ†ï¼ŒæŒ‰total_scoreé™åºæ’åˆ—
    """
    # æ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦ä¸ºç©º
    if df_zj.empty or df_cx.empty or df_ccx.empty:
        print("è­¦å‘Šï¼šæŠ€æœ¯åˆ†ææ•°æ®ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—ç»¼åˆå¾—åˆ†")
        return pd.DataFrame()
    
    # è®¡ç®—ä¸­çº§æŠ€æœ¯æŒ‡æ ‡å¾—åˆ†
    zj_scores = pd.DataFrame()
    zj_scores['index_code'] = df_zj['index_code']
    zj_scores['zjjjdi_score'] = df_zj['zj_jjdi'] * 1.0
    zj_scores['zjdi_score'] = df_zj['zj_di'] * 2.0
    zj_scores['zjdtg_score'] = df_zj['zjdtg'] * 2.0
    zj_scores['zjdtz_score'] = df_zj['zjdtz'] * 0
    # å–æœ€å¤§å€¼
    zj_scores['zj_score'] = zj_scores[['zjjjdi_score','zjdi_score', 'zjdtg_score', 'zjdtz_score']].max(axis=1)
    
    # è®¡ç®—é•¿çº¿æŠ€æœ¯æŒ‡æ ‡å¾—åˆ†
    cx_scores = pd.DataFrame()
    cx_scores['index_code'] = df_cx['index_code']
    cx_scores['cx_jjdi_score'] = df_cx['cx_jjdi'] * 0.5
    cx_scores['cx_di_score'] = df_cx['cx_di'] * 2.5
    cx_scores['cxdtg_score'] = df_cx['cxdtg'] * 4
    cx_scores['cxdtz_score'] = df_cx['cxdtz'] * 0.5
    cx_scores['cx_ding_tzz_score'] = df_cx['cx_ding_tzz'] * -1
    cx_scores['cx_ding_baoliang_score'] = df_cx['cx_ding_baoliang'] * -1
    
    # å–æœ€å¤§å€¼
    cx_scores['cx_final_score'] = cx_scores[['cx_jjdi_score','cx_di_score', 'cxdtg_score', 'cxdtz_score']].max(axis=1)
    cx_scores['cx_score'] = cx_scores['cx_final_score'] + cx_scores['cx_ding_baoliang_score'] + cx_scores['cx_ding_tzz_score']
    
    # è®¡ç®—è¶…é•¿çº¿æŠ€æœ¯æŒ‡æ ‡å¾—åˆ†
    ccx_scores = pd.DataFrame()
    ccx_scores['index_code'] = df_ccx['index_code']
    ccx_scores['ccx_jjdi_score'] = df_ccx['ccx_jjdi'] * 1
    ccx_scores['ccx_di_score'] = df_ccx['ccx_di'] * 3
    ccx_scores['ccxdtg_score'] = df_ccx['ccxdtg'] * 3
    ccx_scores['ccxdtz_score'] = df_ccx['ccxdtz'] * 1
    
    # å–æœ€å¤§å€¼
    ccx_scores['ccx_final_score'] = ccx_scores[['ccx_jjdi_score', 'ccx_di_score', 'ccxdtg_score', 'ccxdtz_score']].max(axis=1)
    ccx_scores['ccx_score'] = ccx_scores['ccx_final_score']
    
    # åˆå¹¶æŠ€æœ¯å¾—åˆ†
    technical_scores = zj_scores[['index_code', 'zj_score']].merge(
        cx_scores[['index_code', 'cx_score']], on='index_code', how='left'
    ).merge(
        ccx_scores[['index_code', 'ccx_score']], on='index_code', how='left'
    )
    
    # è®¡ç®—æŠ€æœ¯æ€»åˆ†
    technical_scores['technical_score'] = technical_scores['zj_score'] + technical_scores['cx_score'] + technical_scores['ccx_score']
    
    # è·å–ä¸»åŠ›å¾—åˆ†
    zhuli_df = zhuli_score()
    zhuli_scores = zhuli_df[['index_code', 'å¾—åˆ†']].rename(columns={'å¾—åˆ†': 'zhuli_score'})
    
    # è·å–ATRè¯„åˆ†ï¼ˆå¦‚æœæä¾›äº†æ—¥æœŸï¼‰
    if date:
        sector_codes = technical_scores['index_code'].tolist()
        atr_scores_dict = get_atr_score(sector_codes, date)
        atr_scores = pd.DataFrame({
            'index_code': list(atr_scores_dict.keys()),
            'atr_score': list(atr_scores_dict.values())
        })
    else:
        # å¦‚æœæ²¡æœ‰æä¾›æ—¥æœŸï¼Œåˆ›å»ºé»˜è®¤çš„ATRå¾—åˆ†
        atr_scores = pd.DataFrame({
            'index_code': technical_scores['index_code'],
            'atr_score': 0
        })
    
    # åˆå¹¶æŠ€æœ¯å¾—åˆ†ã€ä¸»åŠ›å¾—åˆ†å’ŒATRå¾—åˆ†
    final_scores = technical_scores.merge(zhuli_scores, on='index_code', how='left')
    final_scores = final_scores.merge(atr_scores, on='index_code', how='left')
    
    # å¡«å……ç¼ºå¤±çš„ä¸»åŠ›å¾—åˆ†å’ŒATRå¾—åˆ†ä¸º0
    final_scores['zhuli_score'] = final_scores['zhuli_score'].fillna(0)
    final_scores['atr_score'] = final_scores['atr_score'].fillna(0)
    
    # åˆå¹¶æ¿å—æŒ‡æ•°åŸºæœ¬ä¿¡æ¯
    conn = DatabaseManager()
    
    # é¦–å…ˆä»index_k_dailyè¡¨è·å–åç§°ä¿¡æ¯ï¼ˆåŒ…å«è‡ªå®šä¹‰æŒ‡æ•°ä»£ç ï¼‰
    index_info = db_manager.execute_query("SELECT DISTINCT index_code, index_name FROM index_k_daily WHERE index_code LIKE '801%' OR index_code LIKE '850%' OR index_code LIKE '100%' OR index_code LIKE '851%' OR index_code LIKE '852%' OR index_code LIKE '857%' OR index_code LIKE '858%' OR index_code LIKE '859%'", conn)
    
    # ç„¶åä»xinfenleiè¡¨è·å–åç§°ä¿¡æ¯ï¼ˆç”¨äºè¡¥å……ç¼ºå¤±çš„åç§°ï¼‰
    xinfenlei_info = db_manager.execute_query("SELECT DISTINCT sw_xin_code as index_code, sw_name as index_name FROM xinfenlei", conn)
    
    conn.close()
    
    # åˆå¹¶ä¸¤ä¸ªæ•°æ®æºçš„åç§°ä¿¡æ¯
    combined_info = pd.concat([index_info, xinfenlei_info]).drop_duplicates(subset=['index_code'], keep='first')
    
    final_scores = final_scores.merge(combined_info, on='index_code', how='left')
    
    # è®¡ç®—ç»¼åˆæ€»åˆ†
    final_scores['total_score'] = final_scores['technical_score'] + final_scores['zhuli_score'] + final_scores['atr_score']
    
    # è°ƒæ•´åˆ—é¡ºåº
    final_scores = final_scores[['index_code', 'index_name', 'zj_score', 'cx_score', 'ccx_score', 'technical_score', 'zhuli_score', 'atr_score', 'total_score']]
    
    # æŒ‰total_scoreé™åºæ’åº
    final_scores = final_scores.sort_values(by='total_score', ascending=False)
    
    return final_scores




def get_all_standard_index_codes():
    """
    è·å–æ‰€æœ‰æ ‡å‡†æ¿å—æŒ‡æ•°ä»£ç 
    """
    conn = DatabaseManager()
    query = "SELECT DISTINCT index_code FROM index_k_daily WHERE index_code LIKE '801%' ORDER BY index_code"
    df = db_manager.execute_query(query, conn)
    conn.close()
    return df['index_code'].tolist()

def get_custom_concept_names():
    """
    è·å–æ‰€æœ‰è‡ªå®šä¹‰æ¦‚å¿µåç§°
    """
    conn = DatabaseManager()
    query = "SELECT DISTINCT xinfenlei_name FROM xinfenlei ORDER BY xinfenlei_name"
    df = db_manager.execute_query(query, conn)
    conn.close()
    return df['xinfenlei_name'].tolist()

def get_sectors_by_custom_concept(concept_name):
    """
    æ ¹æ®è‡ªå®šä¹‰æ¦‚å¿µåç§°è·å–å¯¹åº”çš„æ¿å—æŒ‡æ•°ä»£ç 
    
    Args:
        concept_name: è‡ªå®šä¹‰æ¦‚å¿µåç§°
    
    Returns:
        list: æ¿å—æŒ‡æ•°ä»£ç åˆ—è¡¨ï¼ˆsw_xin_codeï¼‰
    """
    conn = DatabaseManager()
    query = "SELECT DISTINCT sw_xin_code FROM xinfenlei WHERE xinfenlei_name = ?"
    df = db_manager.execute_query(query, conn, params=[concept_name])
    conn.close()
    return df['sw_xin_code'].tolist()

def display_custom_concept_analysis(concept_name, date):
    """
    æ˜¾ç¤ºè‡ªå®šä¹‰æ¦‚å¿µçš„æ¿å—åˆ†æ
    
    Args:
        concept_name: è‡ªå®šä¹‰æ¦‚å¿µåç§°
        date: åˆ†ææ—¥æœŸ
    """
    st.subheader(f"ğŸ¯ è‡ªå®šä¹‰æ¦‚å¿µåˆ†æ: {concept_name}")
    
    # è·å–è¯¥æ¦‚å¿µä¸‹çš„æ¿å—æŒ‡æ•°ä»£ç 
    sector_codes = get_sectors_by_custom_concept(concept_name)
    
    if not sector_codes:
        st.warning(f"æ¦‚å¿µ '{concept_name}' ä¸‹æ²¡æœ‰æ‰¾åˆ°æ¿å—æ•°æ®")
        return
    
    st.info(f"ğŸ“Š æ¦‚å¿µ '{concept_name}' åŒ…å« {len(sector_codes)} ä¸ªæ¿å—æŒ‡æ•°")
    
    # æ˜¾ç¤ºæ¿å—åˆ—è¡¨
    with st.expander("ğŸ“‹ æŸ¥çœ‹æ¿å—åˆ—è¡¨"):
        db_manager = DatabaseManager()
        query = "SELECT sw_xin_code, sw_name, level FROM xinfenlei WHERE xinfenlei_name = ? ORDER BY sw_xin_code"
        df_sectors = db_manager.execute_query(query, (concept_name,))
        st.dataframe(df_sectors, use_container_width=True)
    
    # è°ƒç”¨ç°æœ‰çš„æ¿å—è¯„åˆ†æ˜¾ç¤ºå‡½æ•°
    display_sector_scores(sector_codes, date)

def get_csv_files_from_folders():
    """
    è·å–5ä¸ªæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰CSVæ–‡ä»¶åˆ—è¡¨
    
    Returns:
        dict: æ–‡ä»¶å¤¹åç§°åˆ°CSVæ–‡ä»¶åˆ—è¡¨çš„æ˜ å°„
    """
    import os
    import glob
    
    folders = {
        "é•¿çº¿æ¶¨å¹…ç­›é€‰": "databases/xunhuan_changxian_zf",
        "æ³¢æ®µæ¶¨å¹…ç­›é€‰": "databases/xunhuan_boduan_zf", 
        "æ³¢æ®µBIASç­›é€‰": "databases/xunhuan_boduan_bias",
        "ä¸­çº§æ¶¨å¹…ç­›é€‰": "databases/xunhuan_zhongji_zf",
        "ä¸­çº§BIASç­›é€‰": "databases/xunhuan_zhongji_bias"
    }
    
    csv_files_dict = {}
    
    for folder_name, folder_path in folders.items():
        if os.path.exists(folder_path):
            csv_files = glob.glob(os.path.join(folder_path, "*.csv"))
            # åªä¿ç•™æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
            csv_files_dict[folder_name] = [os.path.basename(f) for f in csv_files]
        else:
            csv_files_dict[folder_name] = []
    
    return csv_files_dict

def get_special_sector_categories():
    """
    è·å–ç‰¹æ®Šæ¿å—åˆ†ç±»
    
    Returns:
        dict: ç‰¹æ®Šæ¿å—åˆ†ç±»å­—å…¸
    """
    try:
        # ä½¿ç”¨å·²å¯¼å…¥çš„ç‰¹æ®Šæ¿å—è·å–å‡½æ•°
        
        # è·å–å„ç±»ç‰¹æ®Šæ¿å—
        special_categories = {
            "é•¿çº¿å¾ªç¯å±…å‰çš„æ¿å—": get_changxian_zf_bankuai(),
            "æœ€è¿‘3ä¸ªæ³¢æ®µæ¶¨å¹…å¾ªç¯å±…å‰çš„æ¿å—": get_boduan_zf_bankuai(),
            "æœ€è¿‘3ä¸ªæ³¢æ®µBIASå¾ªç¯å±…å‰çš„æ¿å—": get_boduan_bias_bankuai(),
        }
        
        # æ·»åŠ é¢„è®¾çš„ç‰¹æ®Šæ¿å—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        # è¿™äº›å˜é‡éœ€è¦åœ¨å…¨å±€èŒƒå›´å†…å®šä¹‰
        try:
            # é•¿çº¿å¼ºè¶‹åŠ¿æ¿å—
            if 'cxqqs_bankuai' in globals():
                special_categories["é•¿çº¿å¼ºè¶‹åŠ¿æ¿å—"] = cxqqs_bankuai
            
            # è¿‘æœŸæ¶ˆæ¯åšå¼ˆåŸºæœ¬é¢çš„æ¿å—
            if 'jinqi_xiaoxi_bankuai' in globals():
                special_categories["è¿‘æœŸæ¶ˆæ¯åšå¼ˆåŸºæœ¬é¢çš„æ¿å—"] = jinqi_xiaoxi_bankuai
        except:
            pass
        
        return special_categories
        
    except Exception as e:
        st.error(f"è·å–ç‰¹æ®Šæ¿å—åˆ†ç±»å¤±è´¥: {e}")
        return {}

def get_sectors_from_selected_csv_files(selected_files):
    """
    ä»é€‰ä¸­çš„CSVæ–‡ä»¶ä¸­è·å–æ¿å—æŒ‡æ•°ä»£ç 
    
    Args:
        selected_files: é€‰ä¸­çš„CSVæ–‡ä»¶åˆ—è¡¨
    
    Returns:
        list: æ¿å—æŒ‡æ•°ä»£ç åˆ—è¡¨
    """
    import os
    import pandas as pd
    
    all_index_codes = []
    
    for file_name in selected_files:
        # ç¡®å®šæ–‡ä»¶æ‰€åœ¨çš„æ–‡ä»¶å¤¹
        folder_path = None
        if "ç”³ä¸‡æ¿å—ä¸­çº§æ¶¨å¹…" in file_name and "biasç­›é€‰" in file_name:
            folder_path = "databases/xunhuan_zhongji_bias"
        elif "ç”³ä¸‡æ¿å—ä¸­çº§æ¶¨å¹…" in file_name and "æ¶¨å¹…ç­›é€‰" in file_name:
            folder_path = "databases/xunhuan_zhongji_zf"
        elif "ç”³ä¸‡æ¿å—é•¿çº¿æ¶¨å¹…" in file_name:
            folder_path = "databases/xunhuan_changxian_zf"
        elif "ç”³ä¸‡æ¿å—æ³¢æ®µæ¶¨å¹…" in file_name and "biasç­›é€‰" in file_name:
            folder_path = "databases/xunhuan_boduan_bias"
        elif "ç”³ä¸‡æ¿å—æ³¢æ®µæ¶¨å¹…" in file_name and "æ¶¨å¹…ç­›é€‰" in file_name:
            folder_path = "databases/xunhuan_boduan_zf"
    
        if folder_path:
            file_path = os.path.join(folder_path, file_name)
            try:
                df = pd.read_csv(file_path, encoding='utf-8-sig')
                if 'index_code' in df.columns:
                    index_codes = df['index_code'].tolist()
                    all_index_codes.extend(index_codes)
            except Exception as e:
                st.warning(f"è¯»å–æ–‡ä»¶ {file_name} å¤±è´¥: {e}")
                continue
    
    # å»é‡å¹¶è¿”å›
    unique_index_codes = list(set(all_index_codes))
    return unique_index_codes

def get_zhuli_bankuai():
    """
    è·å–ä¸»åŠ›æ¿å—æŒ‡æ•°ä»£ç åˆ—è¡¨
    
    Returns:
        list: ä¸»åŠ›æ¿å—æŒ‡æ•°ä»£ç åˆ—è¡¨
    """
    try:
        # ä½¿ç”¨å·²å¯¼å…¥çš„ä¸»åŠ›æ¿å—è·å–å‡½æ•°
        from applications.sector_screener import get_qualified_sector_codes
        return get_qualified_sector_codes()
    except Exception as e:
        st.error(f"è·å–ä¸»åŠ›æ¿å—å¤±è´¥: {e}")
        return []

def display_zhuli_sector_analysis(sector_codes, date):
    """
    æ˜¾ç¤ºä¸»åŠ›æ¿å—åˆ†æ
    
    Args:
        sector_codes: æ¿å—æŒ‡æ•°ä»£ç åˆ—è¡¨
        date: åˆ†ææ—¥æœŸ
    """
    st.subheader(f"ğŸ’° è‡ªå®šä¹‰ä¸»åŠ›åˆ†æ")
    
    if not sector_codes:
        st.warning("æ²¡æœ‰æ‰¾åˆ°ä¸»åŠ›æ¿å—æ•°æ®")
        return
    
    st.info(f"ğŸ“Š ä¸»åŠ›æ¿å—åŒ…å« {len(sector_codes)} ä¸ªæ¿å—æŒ‡æ•°")
    
    # æ˜¾ç¤ºæ¿å—ä»£ç åˆ—è¡¨
    with st.expander("ğŸ“‹ æŸ¥çœ‹ä¸»åŠ›æ¿å—ä»£ç åˆ—è¡¨"):
        # åˆ›å»ºDataFrameæ˜¾ç¤ºæ¿å—ä»£ç 
        df_codes = pd.DataFrame({
            'index_code': sector_codes,
            'sequence': range(1, len(sector_codes) + 1)
        })
        
        # å°è¯•è·å–æ¿å—åç§°
        try:
            db_manager = DatabaseManager()
            
            # é¦–å…ˆä»index_k_dailyè¡¨è·å–åç§°ä¿¡æ¯
            index_info = db_manager.execute_query("SELECT DISTINCT index_code, index_name FROM index_k_daily WHERE index_code LIKE '801%' OR index_code LIKE '850%' OR index_code LIKE '100%' OR index_code LIKE '851%' OR index_code LIKE '852%' OR index_code LIKE '857%' OR index_code LIKE '858%' OR index_code LIKE '859%'", conn)
            
            # ç„¶åä»xinfenleiè¡¨è·å–åç§°ä¿¡æ¯
            xinfenlei_info = db_manager.execute_query("SELECT DISTINCT sw_xin_code as index_code, sw_name as index_name FROM xinfenlei", conn)
            
            
            # åˆå¹¶ä¸¤ä¸ªæ•°æ®æºçš„åç§°ä¿¡æ¯
            combined_info = pd.concat([index_info, xinfenlei_info]).drop_duplicates(subset=['index_code'], keep='first')
            
            # åˆå¹¶åç§°ä¿¡æ¯
            df_codes = df_codes.merge(combined_info, on='index_code', how='left')
            df_codes['index_name'] = df_codes['index_name'].fillna('æœªçŸ¥')
            
            st.dataframe(df_codes[['sequence', 'index_code', 'index_name']], use_container_width=True)
            
        except Exception as e:
            st.warning(f"è·å–æ¿å—åç§°å¤±è´¥: {e}")
            st.dataframe(df_codes[['sequence', 'index_code']], use_container_width=True)
    
    # è°ƒç”¨ç°æœ‰çš„æ¿å—è¯„åˆ†æ˜¾ç¤ºå‡½æ•°
    display_sector_scores(sector_codes, date)

def display_special_sector_analysis(category_name, sector_codes, date):
    """
    æ˜¾ç¤ºç‰¹æ®Šæ¿å—åˆ†æ
    
    Args:
        category_name: ç‰¹æ®Šæ¿å—åˆ†ç±»åç§°
        sector_codes: æ¿å—æŒ‡æ•°ä»£ç åˆ—è¡¨
        date: åˆ†ææ—¥æœŸ
    """
    st.subheader(f"â­ è‡ªå®šä¹‰ç‰¹æ®Šåˆ†æ: {category_name}")
    
    if not sector_codes:
        st.warning(f"åˆ†ç±» '{category_name}' ä¸‹æ²¡æœ‰æ‰¾åˆ°æ¿å—æ•°æ®")
        return
    
    st.info(f"ğŸ“Š åˆ†ç±» '{category_name}' åŒ…å« {len(sector_codes)} ä¸ªæ¿å—æŒ‡æ•°")
    
    # æ˜¾ç¤ºæ¿å—ä»£ç åˆ—è¡¨
    with st.expander("ğŸ“‹ æŸ¥çœ‹æ¿å—ä»£ç åˆ—è¡¨"):
        # åˆ›å»ºDataFrameæ˜¾ç¤ºæ¿å—ä»£ç 
        df_codes = pd.DataFrame({
            'index_code': sector_codes,
            'sequence': range(1, len(sector_codes) + 1)
        })
        
        # å°è¯•è·å–æ¿å—åç§°
        try:
            db_manager = DatabaseManager()
            
            # é¦–å…ˆä»index_k_dailyè¡¨è·å–åç§°ä¿¡æ¯
            index_info = db_manager.execute_query("SELECT DISTINCT index_code, index_name FROM index_k_daily WHERE index_code LIKE '801%' OR index_code LIKE '850%' OR index_code LIKE '100%' OR index_code LIKE '851%' OR index_code LIKE '852%' OR index_code LIKE '857%' OR index_code LIKE '858%' OR index_code LIKE '859%'", conn)
            
            # ç„¶åä»xinfenleiè¡¨è·å–åç§°ä¿¡æ¯
            xinfenlei_info = db_manager.execute_query("SELECT DISTINCT sw_xin_code as index_code, sw_name as index_name FROM xinfenlei", conn)
            
            
            # åˆå¹¶ä¸¤ä¸ªæ•°æ®æºçš„åç§°ä¿¡æ¯
            combined_info = pd.concat([index_info, xinfenlei_info]).drop_duplicates(subset=['index_code'], keep='first')
            
            # åˆå¹¶åç§°ä¿¡æ¯
            df_codes = df_codes.merge(combined_info, on='index_code', how='left')
            df_codes['index_name'] = df_codes['index_name'].fillna('æœªçŸ¥')
            
            st.dataframe(df_codes[['sequence', 'index_code', 'index_name']], use_container_width=True)
            
        except Exception as e:
            st.warning(f"è·å–æ¿å—åç§°å¤±è´¥: {e}")
            st.dataframe(df_codes[['sequence', 'index_code']], use_container_width=True)
    
    # è°ƒç”¨ç°æœ‰çš„æ¿å—è¯„åˆ†æ˜¾ç¤ºå‡½æ•°
    display_sector_scores(sector_codes, date)

def analyze_sector_indices(date: str, index_codes: List[str] = None):
    """
    å®Œæ•´çš„æ¿å—æŒ‡æ•°æŠ€æœ¯åˆ†ææµç¨‹
    
    Args:
        date: åˆ†ææ—¥æœŸ
        index_codes: æ¿å—æŒ‡æ•°ä»£ç åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ†ææ‰€æœ‰æ ‡å‡†æ¿å—æŒ‡æ•°
    
    Returns:
        åŒ…å«æŠ€æœ¯å¾—åˆ†çš„DataFrame
    """
    print(f"å¼€å§‹åˆ†ææ¿å—æŒ‡æ•°æŠ€æœ¯çŠ¶æ€ï¼Œæ—¥æœŸï¼š{date}")
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæŒ‡æ•°ä»£ç ï¼Œåˆ™è·å–æ‰€æœ‰æ ‡å‡†æ¿å—æŒ‡æ•°
    if index_codes is None:
        index_codes = get_all_standard_index_codes()
        print(f"å°†åˆ†æ {len(index_codes)} ä¸ªæ ‡å‡†æ¿å—æŒ‡æ•°")
    
    # æ­¥éª¤1ï¼šè·å–ä¸­çº§æŠ€æœ¯çŠ¶æ€
    print("æ­£åœ¨åˆ†æä¸­çº§æŠ€æœ¯çŠ¶æ€...")
    df_zj = get_jishu_zj(index_codes, date)
    
    # æ­¥éª¤2ï¼šè·å–é•¿çº¿æŠ€æœ¯çŠ¶æ€
    print("æ­£åœ¨åˆ†æé•¿çº¿æŠ€æœ¯çŠ¶æ€...")
    df_cx = get_jishu_cx(index_codes, date)
    
    # æ­¥éª¤3ï¼šè·å–è¶…é•¿çº¿æŠ€æœ¯çŠ¶æ€
    print("æ­£åœ¨åˆ†æè¶…é•¿çº¿æŠ€æœ¯çŠ¶æ€...")
    df_ccx = get_jishu_ccx(index_codes, date)
    
    # æ­¥éª¤4ï¼šè®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆæŠ€æœ¯å¾—åˆ†+ä¸»åŠ›å¾—åˆ†ï¼‰
    print("æ­£åœ¨è®¡ç®—ç»¼åˆå¾—åˆ†...")
    final_scores = calculate_comprehensive_scores(df_zj, df_cx, df_ccx)
    
    print(f"åˆ†æå®Œæˆï¼å…±åˆ†æäº† {len(final_scores)} ä¸ªæ¿å—æŒ‡æ•°")
    return final_scores

def zhuli_score():
    """
    è¯»å–å¹¶è®¡ç®—æ¿å—å¸‚å€¼åˆ†æå¾—åˆ†
    è¯»å–databases/sector_market_cap_analysis.xlsx
    å¦‚æœã€Šè¶…å¼ºã€‹å­—æ®µçš„å€¼ >0.8å¾—åˆ†1ï¼Œå¦‚æœã€Šè¶…è¶…å¼ºã€‹å­—æ®µçš„å€¼>0.6å¾—åˆ†1ï¼Œ
    å¦‚æœã€Šå¤§é«˜ã€‹å­—æ®µçš„å€¼>0.7å¾—åˆ†1ï¼Œå¦‚æœã€Šå›½ä¼ã€‹å­—æ®µçš„å€¼>0.7å¾—åˆ†1ï¼Œ
    å¦‚æœæ¿å—å±äºchangxian_bankuaiï¼ˆé•¿çº¿å¾ªç¯å±…å‰ï¼‰ï¼Œå¾—åˆ†0.6ï¼Œç„¶åæ±‡æ€»å¾—åˆ†ã€‚
    åŒæ—¶å°†index_codeåç¼€ä».SIæ”¹ä¸º.ZS
    """
    # è¯»å–Excelæ–‡ä»¶ - ä½¿ç”¨ç›¸å¯¹è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    excel_path = os.path.join(current_dir, '..', '..', 'databases', 'sector_market_cap_analysis.xlsx')
    excel_path = os.path.abspath(excel_path)
    df = pd.read_excel(excel_path)
    
    # å°†index_codeåç¼€ä».SIæ”¹ä¸º.ZSï¼ˆæ ‡å‡†æ¿å—ï¼‰
    df['index_code'] = df['index_code'].str.replace('.SI', '.ZS')
    
    # è·å–é•¿çº¿å¾ªç¯å±…å‰çš„æ¿å—åˆ—è¡¨
    changxian_bankuai = get_changxian_zf_bankuai()
    
    # è®¡ç®—å¾—åˆ†
    df['å¾—åˆ†'] = 0
    df['å¾—åˆ†'] = df['å¾—åˆ†'] + (df['è¶…å¼º'] > 0.8) * 1
    df['å¾—åˆ†'] = df['å¾—åˆ†'] + (df['è¶…è¶…å¼º'] > 0.6) * 1
    df['å¾—åˆ†'] = df['å¾—åˆ†'] + (df['å¤§é«˜'] > 0.7) * 1
    df['å¾—åˆ†'] = df['å¾—åˆ†'] + (df['å›½ä¼'] > 0.7) * 1
    # å¦‚æœæ¿å—å±äºé•¿çº¿å¾ªç¯å±…å‰ï¼Œå¾—åˆ†1
    df['å¾—åˆ†'] = df['å¾—åˆ†'] + df['index_code'].isin(changxian_bankuai) * 0.6
    
    return df

#å¢åŠ ä¸€ä¸ªå­—æ®µatrï¼Œå°±æ˜¯è®¡ç®—æ¿å—æŒ‡æ•°çš„atrï¼Œç”¨20å¤©atrï¼Œå¦å¤–æ—¶é—´å°±æ˜¯ã€Šè¯·é€‰æ‹©è·Ÿè¸ªæ—¥æœŸ:ã€‹
def get_atr(index_code, date, N=20):
    """
    è·å–æ¿å—æŒ‡æ•°çš„ATRå€¼
    é€šè¿‡è°ƒç”¨indicators.pyä¸­çš„ATRå‡½æ•°æ¥è®¡ç®—20å¤©ATR
    
    å‚æ•°:
    index_code: æ¿å—æŒ‡æ•°ä»£ç 
    date: è®¡ç®—æ—¥æœŸ
    N: ATRå‘¨æœŸï¼Œé»˜è®¤20å¤©
    
    è¿”å›:
    float: ATRå€¼
    """
    # è·å–æ¿å—æŒ‡æ•°çš„å†å²æ•°æ®
    df = get_daily_data_for_sector_backtest(index_code, date)
    
    if df.empty or len(df) < N:
        return None
    
    # ä»v2é¡¹ç›®çš„indicatorsæ¨¡å—å¯¼å…¥ATRå‡½æ•°
    from core.utils.indicators import ATR
    
    # å‡†å¤‡æ•°æ®ï¼šéœ€è¦æ”¶ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·
    close = df['close'].values
    high = df['high'].values
    low = df['low'].values
    
    # è®¡ç®—ATR (è¿”å›ATRåºåˆ—å’ŒTRåºåˆ—)
    atr_series, tr_series = ATR(close, high, low, N)
    
    # è¿”å›æœ€æ–°çš„ATRå€¼
    return atr_series[-1] if len(atr_series) > 0 else None

##å¢åŠ ä¸€ä¸ªå¯¹æ¿å—è¯„åˆ†çš„å­—æ®µatr_scoreï¼Œå°±æ˜¯è®¡ç®—æ¿å—æŒ‡æ•°çš„atrï¼Œç”¨20å¤©atrï¼Œå¦å¤–æ—¶é—´å°±æ˜¯ã€Šè¯·é€‰æ‹©è·Ÿè¸ªæ—¥æœŸ:ã€‹ï¼Œå¦‚æœatrè¿›è¡Œæ’åºï¼Œå¦‚æœåœ¨quantile(0.49)ä»¥ä¸‹ï¼Œå¾—åˆ†1ï¼Œå¦åˆ™å¾—åˆ†0ã€‚
def get_atr_score(index_code_list, date):
    """
    è·å–æ¿å—æŒ‡æ•°çš„ATRè¯„åˆ†
    è®¡ç®—æ‰€æœ‰æ¿å—çš„ATRå€¼ï¼Œç„¶åæ ¹æ®åˆ†ä½æ•°è¿›è¡Œè¯„åˆ†
    
    å‚æ•°:
    index_code_list: æ¿å—æŒ‡æ•°ä»£ç åˆ—è¡¨
    date: è®¡ç®—æ—¥æœŸ
    
    è¿”å›:
    dict: {index_code: atr_score} çš„å­—å…¸ï¼ŒATRåœ¨49%åˆ†ä½æ•°ä»¥ä¸‹å¾—1åˆ†ï¼Œå¦åˆ™å¾—0åˆ†
    """
    atr_dict = {}
    atr_values = []
    
    # å…ˆè®¡ç®—æ‰€æœ‰æ¿å—çš„ATRå€¼
    for index_code in index_code_list:
        atr = get_atr(index_code, date)
        if atr is not None:
            atr_dict[index_code] = atr
            atr_values.append(atr)
    
    if not atr_values:
        return {code: 0 for code in index_code_list}
    
    # è®¡ç®—49%åˆ†ä½æ•°
    import numpy as np
    atr_threshold = np.quantile(atr_values, 0.49)
    
    # æ ¹æ®åˆ†ä½æ•°è¯„åˆ†
    atr_scores = {}
    for index_code in index_code_list:
        if index_code in atr_dict:
            atr_scores[index_code] = 1 if atr_dict[index_code] < atr_threshold else 0
        else:
            atr_scores[index_code] = 0
    
    return atr_scores



def test_comprehensive_scores():
    """
    æµ‹è¯•ç»¼åˆå¾—åˆ†è®¡ç®—åŠŸèƒ½
    """
    print("=== æµ‹è¯•ä¸»åŠ›å¾—åˆ†åŠŸèƒ½ ===")
    zhuli_df = zhuli_score()
    print("ä¸»åŠ›å¾—åˆ†å‰5å:")
    print(zhuli_df[['index_code', 'æ¿å—åç§°', 'å¾—åˆ†']].head())
    
    print("\n=== æµ‹è¯•ç»¼åˆå¾—åˆ†è®¡ç®— ===")
    # åˆ›å»ºæ¨¡æ‹Ÿçš„æŠ€æœ¯æŒ‡æ ‡æ•°æ®
    test_codes = ["801050.ZS", "801010.ZS", "801030.ZS", "801160.ZS", "801720.ZS"]
    
    # æ¨¡æ‹ŸæŠ€æœ¯æŒ‡æ ‡æ•°æ®
    df_zj = pd.DataFrame({
        'index_code': test_codes,
        'zj_jjdi': [1, 0, 1, 1, 0],
        'zj_di': [0, 1, 0, 1, 1],
        'zjdtg': [0, 0, 1, 0, 1],
        'zjdtz': [0, 0, 0, 0, 0]
    })
    
    df_cx = pd.DataFrame({
        'index_code': test_codes,
        'cx_jjdi': [1, 0, 1, 1, 0],
        'cx_di': [0, 1, 0, 1, 1],
        'cxdtg': [0, 0, 1, 0, 1],
        'cxdtz': [0, 0, 0, 0, 0],
        'cx_ding_tzz': [0, 0, 0, 0, 0],
        'cx_ding_baoliang': [0, 0, 0, 0, 0]
    })
    
    df_ccx = pd.DataFrame({
        'index_code': test_codes,
        'ccx_jjdi': [1, 0, 1, 1, 0],
        'ccx_di': [0, 1, 0, 1, 1],
        'ccxdtg': [0, 0, 1, 0, 1],
        'ccxdtz': [0, 0, 0, 0, 0]
    })
    
    # è®¡ç®—ç»¼åˆå¾—åˆ†
    comprehensive_scores = calculate_comprehensive_scores(df_zj, df_cx, df_ccx)
    print("ç»¼åˆå¾—åˆ†ç»“æœ:")
    print(comprehensive_scores[['index_code', 'index_name', 'zj_score', 'cx_score', 'ccx_score', 'technical_score', 'zhuli_score', 'total_score']])

def main():
    """ä¸»ç•Œé¢å‡½æ•°"""
    # é¡µé¢é…ç½®
    st.set_page_config(
        page_title="é€‰æ‹©æ¿å—è¯„åˆ†åˆ†æç³»ç»Ÿ",
        page_icon="ğŸ“Š",
        layout="wide"
    )
    
    # ç¡®å®šè·Ÿè¸ªçš„æ—¶é—´ï¼šç”¨æ¡†æ¥è·å–æ—¶é—´
    date1 = st.sidebar.date_input('è¯·é€‰æ‹©è·Ÿè¸ªæ—¥æœŸ:', date.today())
    
    # å°†date1è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
    analysis_date = date1.strftime('%Y-%m-%d')
    
    # å°†åˆ†ææ—¥æœŸå­˜å‚¨åˆ°session stateä¸­
    st.session_state['analysis_date'] = analysis_date
    
    st.title("ğŸ“Š æ¿å—æŒ‡æ•°è¯„åˆ†åˆ†æç³»ç»Ÿ")
    st.caption(f"åˆ†ææ—¥æœŸ: {analysis_date}")
    
    # åˆ›å»ºä¾§è¾¹æ é€‰é¡¹
    st.sidebar.title("åŠŸèƒ½é€‰æ‹©")
    analysis_type = st.sidebar.selectbox(
        "é€‰æ‹©åˆ†æç±»å‹:",
        ["ç”³ä¸‡è¡Œä¸šæ¿å—åˆ†æ", "è‡ªå®šä¹‰æ¿å—åˆ†æ", "è‡ªå®šä¹‰å¢é‡åˆ†æ", "è‡ªå®šä¹‰æ¦‚å¿µåˆ†æ", "è‡ªå®šä¹‰ç‰¹æ®Šåˆ†æ", "è‡ªå®šä¹‰ä¸»åŠ›åˆ†æ", "ä¸»åŠ›å¾—åˆ†åˆ†æ", "ç³»ç»Ÿæµ‹è¯•"]
    )
    
    if analysis_type == "ç”³ä¸‡è¡Œä¸šæ¿å—åˆ†æ":
        display_sw_sector_hierarchy()
    
    elif analysis_type == "è‡ªå®šä¹‰æ¿å—åˆ†æ":
        st.subheader("ğŸ”§ è‡ªå®šä¹‰æ¿å—åˆ†æ")
        
        # è¾“å…¥æ¿å—ä»£ç 
        custom_codes = st.text_area(
            "è¯·è¾“å…¥æ¿å—æŒ‡æ•°ä»£ç ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œå¦‚ï¼š100001.ZSï¼‰:",
            # value="801050.ZS\n801010.ZS\n801030.ZS\n851243.ZS",
            value = "100001.ZS\n100002.ZS\n100003.ZS\n100004.ZS\n100005.ZS\n100006.ZS\n100007.ZS\n100008.ZS\n100009.ZS",
            height=100
        )
        
        if st.button("å¼€å§‹åˆ†æ"):
            codes = [code.strip() for code in custom_codes.split('\n') if code.strip()]
            if codes:
                display_sector_scores(codes, analysis_date)
            else:
                st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„æ¿å—æŒ‡æ•°ä»£ç ")
    
    elif analysis_type == "è‡ªå®šä¹‰å¢é‡åˆ†æ":
        st.subheader("ğŸ”§ è‡ªå®šä¹‰å¢é‡åˆ†æ")
        
        # è¾“å…¥æ¿å—ä»£ç 
        custom_codes = st.text_area(
            "è¯·è¾“å…¥æ¿å—æŒ‡æ•°ä»£ç ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œå¦‚ï¼š100001.ZSï¼‰:",
            # value="801050.ZS\n801010.ZS\n801030.ZS\n851243.ZS",
            value = "801083.ZS\n801726.ZS\n801764.ZS\n801053.ZS\n801050.ZS\n801017.ZS\n801993.ZS\n801737.ZS\n801038.ZS\n801181.ZS\n801116.ZS",
            height=100
        )
        
        if st.button("å¼€å§‹åˆ†æ"):
            codes = [code.strip() for code in custom_codes.split('\n') if code.strip()]
            if codes:
                display_sector_scores(codes, analysis_date)
            else:
                st.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„æ¿å—æŒ‡æ•°ä»£ç ")
    
    elif analysis_type == "è‡ªå®šä¹‰æ¦‚å¿µåˆ†æ":
        st.subheader("ğŸ¯ è‡ªå®šä¹‰æ¦‚å¿µåˆ†æ")
        
        # è·å–æ‰€æœ‰è‡ªå®šä¹‰æ¦‚å¿µ
        try:
            concept_names = get_custom_concept_names()
            
            if not concept_names:
                st.error("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è‡ªå®šä¹‰æ¦‚å¿µæ•°æ®")
                return
            
            # é€‰æ‹©æ¦‚å¿µ
            selected_concept = st.selectbox(
                "è¯·é€‰æ‹©è¦åˆ†æçš„è‡ªå®šä¹‰æ¦‚å¿µ:",
                concept_names,
                help="é€‰æ‹©ä¸€ä¸ªè‡ªå®šä¹‰æ¦‚å¿µï¼Œç³»ç»Ÿå°†åˆ†æè¯¥æ¦‚å¿µä¸‹æ‰€æœ‰æ¿å—çš„æŠ€æœ¯ã€ä¸»åŠ›å’ŒATRè¯„åˆ†"
            )
            
            # æ˜¾ç¤ºæ¦‚å¿µä¿¡æ¯
            if selected_concept:
                sector_count = len(get_sectors_by_custom_concept(selected_concept))
                st.info(f"ğŸ“Š æ¦‚å¿µ '{selected_concept}' åŒ…å« {sector_count} ä¸ªæ¿å—æŒ‡æ•°")
                
                if st.button("å¼€å§‹åˆ†æ", key="custom_concept_analysis"):
                    if sector_count > 0:
                        display_custom_concept_analysis(selected_concept, analysis_date)
                    else:
                        st.warning(f"æ¦‚å¿µ '{selected_concept}' ä¸‹æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ¿å—æ•°æ®")
        
        except Exception as e:
            st.error(f"è·å–è‡ªå®šä¹‰æ¦‚å¿µæ•°æ®æ—¶å‡ºé”™: {e}")
    
    elif analysis_type == "è‡ªå®šä¹‰ç‰¹æ®Šåˆ†æ":
        st.subheader("â­ è‡ªå®šä¹‰ç‰¹æ®Šåˆ†æ")
        
        # è·å–CSVæ–‡ä»¶åˆ—è¡¨
        try:
            csv_files_dict = get_csv_files_from_folders()
            
            if not any(csv_files_dict.values()):
                st.error("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•CSVæ–‡ä»¶æ•°æ®")
                return
            
            # æ˜¾ç¤ºæ–‡ä»¶æ¦‚è§ˆ
            total_files = sum(len(files) for files in csv_files_dict.values())
            st.info(f"ğŸ“Š æ‰¾åˆ° {total_files} ä¸ªCSVæ–‡ä»¶")
            
            # æ˜¾ç¤ºæ¯ä¸ªæ–‡ä»¶å¤¹çš„æ–‡ä»¶æ•°é‡
            for folder_name, files in csv_files_dict.items():
                if files:
                    st.text(f"ğŸ“ {folder_name}: {len(files)} ä¸ªæ–‡ä»¶")
            
            # åˆ›å»ºå¤šé€‰æ¡†é€‰æ‹©CSVæ–‡ä»¶
            all_files = []
            for folder_name, files in csv_files_dict.items():
                for file in files:
                    all_files.append(f"{folder_name}/{file}")
            
            if all_files:
                selected_files = st.multiselect(
                    "è¯·é€‰æ‹©è¦åˆ†æçš„CSVæ–‡ä»¶:",
                    all_files,
                    help="å¯ä»¥é€‰æ‹©å¤šä¸ªCSVæ–‡ä»¶è¿›è¡Œåˆ†æï¼Œç³»ç»Ÿå°†åˆå¹¶è¿™äº›æ–‡ä»¶ä¸­çš„æ¿å—æŒ‡æ•°ä»£ç "
                )
                
                # æ˜¾ç¤ºé€‰æ‹©ä¿¡æ¯
                if selected_files:
                    st.success(f"âœ… å·²é€‰æ‹© {len(selected_files)} ä¸ªCSVæ–‡ä»¶")
                    
                    # æ˜¾ç¤ºé€‰ä¸­çš„æ–‡ä»¶åˆ—è¡¨
                    with st.expander("ğŸ“‹ æŸ¥çœ‹é€‰ä¸­çš„æ–‡ä»¶"):
                        for file in selected_files:
                            st.text(f"â€¢ {file}")
                    
                    # è·å–æ¿å—æŒ‡æ•°ä»£ç 
                    file_names = [file.split('/')[-1] for file in selected_files]  # åªå–æ–‡ä»¶åéƒ¨åˆ†
                    sector_codes = get_sectors_from_selected_csv_files(file_names)
                    sector_count = len(sector_codes) if sector_codes else 0
                    
                    if sector_count > 0:
                        st.success(f"âœ… åˆå¹¶ååŒ…å« {sector_count} ä¸ªæ¿å—æŒ‡æ•°")
                        
                        # æ˜¾ç¤ºå‰å‡ ä¸ªæ¿å—ä»£ç ä½œä¸ºé¢„è§ˆ
                        preview_codes = sector_codes[:5] if len(sector_codes) > 5 else sector_codes
                        st.text(f"é¢„è§ˆæ¿å—ä»£ç : {', '.join(preview_codes)}")
                        if len(sector_codes) > 5:
                            st.text(f"... è¿˜æœ‰ {len(sector_codes) - 5} ä¸ªæ¿å—")
                        
                        if st.button("å¼€å§‹åˆ†æ", key="special_sector_analysis"):
                            display_special_sector_analysis("è‡ªå®šä¹‰ç‰¹æ®Šåˆ†æ", sector_codes, analysis_date)
                    else:
                        st.warning("é€‰ä¸­çš„æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ¿å—æ•°æ®")
                else:
                    st.info("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªCSVæ–‡ä»¶è¿›è¡Œåˆ†æ")
            else:
                st.warning("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¯ç”¨çš„CSVæ–‡ä»¶")
        
        except Exception as e:
            st.error(f"è·å–CSVæ–‡ä»¶æ•°æ®æ—¶å‡ºé”™: {e}")
            st.text("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            st.text(str(e))
    
    elif analysis_type == "è‡ªå®šä¹‰ä¸»åŠ›åˆ†æ":
        st.subheader("ğŸ’° è‡ªå®šä¹‰ä¸»åŠ›åˆ†æ")
        
        # è·å–ä¸»åŠ›æ¿å—æŒ‡æ•°ä»£ç 
        try:
            zhuli_codes = get_zhuli_bankuai()
            
            if not zhuli_codes:
                st.error("æ²¡æœ‰æ‰¾åˆ°ä¸»åŠ›æ¿å—æ•°æ®")
                st.info("ğŸ’¡ **è¯´æ˜**: ä¸»åŠ›æ¿å—æ•°æ®æ¥æºäºå¸‚å€¼åˆ†æï¼Œç­›é€‰æ¡ä»¶åŒ…æ‹¬ï¼š")
                st.text("1. (å›½ä¼ > 0.4) & (è¶…å¼º > 0.7)")
                st.text("2. æˆ–è€… è¶…è¶…å¼º > 0.6")
                st.text("3. æˆ–è€… å¤§é«˜ > 0.8")
                return
            
            # æ˜¾ç¤ºä¸»åŠ›æ¿å—æ¦‚è§ˆ
            st.success(f"âœ… æ‰¾åˆ° {len(zhuli_codes)} ä¸ªä¸»åŠ›æ¿å—")
            
            # æ˜¾ç¤ºç­›é€‰æ¡ä»¶è¯´æ˜
            with st.expander("ğŸ“‹ ä¸»åŠ›æ¿å—ç­›é€‰æ¡ä»¶"):
                st.info("""
                **ç­›é€‰æ¡ä»¶**ï¼š
                1. (å›½ä¼ > 0.4) & (è¶…å¼º > 0.7)
                2. æˆ–è€… è¶…è¶…å¼º > 0.6  
                3. æˆ–è€… å¤§é«˜ > 0.8
                
                **æ•°æ®æ¥æº**ï¼šsector_market_cap_analysis.xlsx
                """)
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªæ¿å—ä»£ç ä½œä¸ºé¢„è§ˆ
            if zhuli_codes:
                preview_codes = zhuli_codes[:5] if len(zhuli_codes) > 5 else zhuli_codes
                st.text(f"é¢„è§ˆæ¿å—ä»£ç : {', '.join(preview_codes)}")
                if len(zhuli_codes) > 5:
                    st.text(f"... è¿˜æœ‰ {len(zhuli_codes) - 5} ä¸ªæ¿å—")
            
            if st.button("å¼€å§‹åˆ†æ", key="zhuli_sector_analysis"):
                display_zhuli_sector_analysis(zhuli_codes, analysis_date)
        
        except Exception as e:
            st.error(f"è·å–ä¸»åŠ›æ¿å—æ•°æ®æ—¶å‡ºé”™: {e}")
            st.text("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
            st.text(str(e))
    
    elif analysis_type == "ä¸»åŠ›å¾—åˆ†åˆ†æ":
        st.subheader("ğŸ’° ä¸»åŠ›å¾—åˆ†åˆ†æ")
        
        # æ˜¾ç¤ºä¸»åŠ›å¾—åˆ†æ•°æ®
        zhuli_df = zhuli_score()
        
        # æ˜¾ç¤ºä¸»åŠ›å¾—åˆ†ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("æ€»æ¿å—æ•°", len(zhuli_df))
        with col2:
            st.metric("å¹³å‡å¾—åˆ†", f"{zhuli_df['å¾—åˆ†'].mean():.2f}")
        with col3:
            st.metric("æœ€é«˜å¾—åˆ†", zhuli_df['å¾—åˆ†'].max())
        with col4:
            st.metric("å¾—åˆ†>0æ¿å—æ•°", len(zhuli_df[zhuli_df['å¾—åˆ†'] > 0]))
        
        # æ˜¾ç¤ºå¾—åˆ†åˆ†å¸ƒ
        st.subheader("ğŸ“Š ä¸»åŠ›å¾—åˆ†åˆ†å¸ƒ")
        import plotly.express as px
        
        fig1 = px.histogram(zhuli_df, x='å¾—åˆ†', title="ä¸»åŠ›å¾—åˆ†åˆ†å¸ƒ")
        st.plotly_chart(fig1, use_container_width=True)
        
        # æ˜¾ç¤ºé«˜åˆ†æ¿å—
        st.subheader("ğŸ† é«˜åˆ†æ¿å—")
        high_score_df = zhuli_df[zhuli_df['å¾—åˆ†'] >= 2].sort_values('å¾—åˆ†', ascending=False)
        if not high_score_df.empty:
            st.dataframe(high_score_df[['index_code', 'æ¿å—åç§°', 'è¶…å¼º', 'è¶…è¶…å¼º', 'å¤§é«˜', 'å›½ä¼', 'å¾—åˆ†']], use_container_width=True)
        else:
            st.info("æš‚æ— å¾—åˆ†â‰¥2çš„æ¿å—")
        
        # æ˜¾ç¤ºå®Œæ•´æ•°æ®
        if st.checkbox("æ˜¾ç¤ºå®Œæ•´ä¸»åŠ›å¾—åˆ†æ•°æ®"):
            st.dataframe(zhuli_df, use_container_width=True)
    
    elif analysis_type == "ç³»ç»Ÿæµ‹è¯•":
        st.subheader("ğŸ§ª ç³»ç»Ÿæµ‹è¯•")
        
        if st.button("è¿è¡Œç³»ç»Ÿæµ‹è¯•"):
            with st.spinner("æ­£åœ¨è¿è¡Œæµ‹è¯•..."):
                test_comprehensive_scores()
        
        # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
        st.subheader("ğŸ“‹ ç³»ç»Ÿä¿¡æ¯")
        col1, col2 = st.columns(2)
        
        with col1:
            st.info(f"""
            **æ•°æ®åº“è¿æ¥**: âœ… æ­£å¸¸
            **æŠ€æœ¯åˆ†ææ¨¡å—**: âœ… å·²åŠ è½½
            **ä¸»åŠ›åˆ†ææ¨¡å—**: âœ… å·²åŠ è½½
            **å¯è§†åŒ–æ¨¡å—**: âœ… å·²åŠ è½½
            """)
        
        with col2:
            # è·å–å¯ç”¨æ¿å—æ•°é‡
            try:
                all_codes = get_all_standard_index_codes()
                st.info(f"""
                **å¯ç”¨æ¿å—æŒ‡æ•°**: {len(all_codes)} ä¸ª
                **ç”³ä¸‡è¡Œä¸šæ•°æ®**: âœ… å·²åŠ è½½
                **åˆ†ææ—¥æœŸ**: {date}
                **ç³»ç»ŸçŠ¶æ€**: ğŸŸ¢ è¿è¡Œæ­£å¸¸
                """)
            except Exception as e:
                st.error(f"ç³»ç»Ÿæ£€æŸ¥å¤±è´¥: {e}")

if __name__ == "__main__":
    # è¿è¡Œä¸»ç•Œé¢
    # ä½¿ç”¨ streamlit run å‘½ä»¤æ—¶æŒ‡å®šç«¯å£: streamlit run xuangu_bankuai.py --server.port 8501
    main()
